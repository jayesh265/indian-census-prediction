{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 5 columns):\n",
      "States    23 non-null object\n",
      "2011      22 non-null float64\n",
      "2021      23 non-null float64\n",
      "2031      23 non-null float64\n",
      "2041      23 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 1.0+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "popgro = pd.read_csv(r\"C:\\Users\\MAHE\\Downloads\\Population_Growth - Population_Growth.csv\")\n",
    "popgro.head\n",
    "popgro.shape\n",
    "tfr=pd.read_csv(r\"C:\\Users\\MAHE\\Downloads\\TFR.csv\")\n",
    "tfr.head\n",
    "tfr.shape\n",
    "pop200=pd.read_csv(r\"C:\\Users\\MAHE\\Downloads\\2001.csv\")\n",
    "pop200.head\n",
    "pop200.shape\n",
    "census2011=pd.read_csv(r\"C:\\Users\\MAHE\\Downloads\\Census_2011.csv\")\n",
    "census2011.head\n",
    "census2011.shape\n",
    "sexr=pd.read_csv(r\"C:\\Users\\MAHE\\Downloads\\Sex_Ratio_Female_to_male_.csv\")\n",
    "sexr.head\n",
    "sexr.shape\n",
    "age=pd.read_csv(r\"C:\\Users\\MAHE\\Downloads\\Age Structure - Sheet1.csv\")\n",
    "age1=pd.read_csv(r\"C:\\Users\\MAHE\\Downloads\\Age Structure - Sheet1 (1) - Age Structure - Sheet1 (1).csv\")\n",
    "age.head\n",
    "age.shape\n",
    "pop=pd.read_csv(r\"C:\\Users\\MAHE\\Downloads\\Population.csv\")\n",
    "pop.head\n",
    "pop.shape\n",
    "life=pd.read_csv(r\"C:\\Users\\MAHE\\Downloads\\Longevity data - Sheet1 (1).csv\")\n",
    "prese=pd.read_csv(r\"C:\\Users\\MAHE\\Downloads\\Sex_Ratio_Female_to_male_ - Sex_Ratio_Female_to_male_.csv\")\n",
    "popgro.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 5)"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popgro.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 7)"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfr.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 118)"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census2011.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 8)"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 13)"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "popgro.fillna(popgro.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 5)"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 7 columns):\n",
      "States    23 non-null object\n",
      "2001      23 non-null float64\n",
      "2011      23 non-null float64\n",
      "2016      23 non-null float64\n",
      "2021      23 non-null float64\n",
      "2031      23 non-null float64\n",
      "2041      23 non-null float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 1.4+ KB\n"
     ]
    }
   ],
   "source": [
    "tfr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfr['2001'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfr['2011'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfr['2016'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfr['2021'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfr['2031'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfr['2041'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 5)"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "life.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 5)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36 entries, 0 to 35\n",
      "Data columns (total 8 columns):\n",
      "State     36 non-null object\n",
      "1951      35 non-null float64\n",
      "1961      36 non-null int64\n",
      "1971      36 non-null int64\n",
      "1981      36 non-null int64\n",
      "1991      36 non-null int64\n",
      "2001      36 non-null int64\n",
      "2011      36 non-null int64\n",
      "dtypes: float64(1), int64(6), object(1)\n",
      "memory usage: 2.3+ KB\n"
     ]
    }
   ],
   "source": [
    "sexr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sexr.fillna(sexr.mean(axis=1))\n",
    "sexr.fillna(sexr.mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 640 entries, 0 to 639\n",
      "Columns: 118 entries, District code to Total_Power_Parity\n",
      "dtypes: int64(116), object(2)\n",
      "memory usage: 590.1+ KB\n"
     ]
    }
   ],
   "source": [
    "census2011.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District code</th>\n",
       "      <th>Population</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Literate</th>\n",
       "      <th>Male_Literate</th>\n",
       "      <th>Female_Literate</th>\n",
       "      <th>SC</th>\n",
       "      <th>Male_SC</th>\n",
       "      <th>Female_SC</th>\n",
       "      <th>...</th>\n",
       "      <th>Power_Parity_Rs_90000_150000</th>\n",
       "      <th>Power_Parity_Rs_45000_150000</th>\n",
       "      <th>Power_Parity_Rs_150000_240000</th>\n",
       "      <th>Power_Parity_Rs_240000_330000</th>\n",
       "      <th>Power_Parity_Rs_150000_330000</th>\n",
       "      <th>Power_Parity_Rs_330000_425000</th>\n",
       "      <th>Power_Parity_Rs_425000_545000</th>\n",
       "      <th>Power_Parity_Rs_330000_545000</th>\n",
       "      <th>Power_Parity_Above_Rs_545000</th>\n",
       "      <th>Total_Power_Parity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>640.000000</td>\n",
       "      <td>6.400000e+02</td>\n",
       "      <td>6.400000e+02</td>\n",
       "      <td>6.400000e+02</td>\n",
       "      <td>6.400000e+02</td>\n",
       "      <td>6.400000e+02</td>\n",
       "      <td>6.400000e+02</td>\n",
       "      <td>6.400000e+02</td>\n",
       "      <td>6.400000e+02</td>\n",
       "      <td>6.400000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>320.500000</td>\n",
       "      <td>1.891961e+06</td>\n",
       "      <td>9.738598e+05</td>\n",
       "      <td>9.181011e+05</td>\n",
       "      <td>1.193186e+06</td>\n",
       "      <td>6.793182e+05</td>\n",
       "      <td>5.138675e+05</td>\n",
       "      <td>3.146537e+05</td>\n",
       "      <td>1.617739e+05</td>\n",
       "      <td>1.528798e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>786.046875</td>\n",
       "      <td>1696.456250</td>\n",
       "      <td>294.000000</td>\n",
       "      <td>215.300000</td>\n",
       "      <td>509.300000</td>\n",
       "      <td>194.204688</td>\n",
       "      <td>261.245313</td>\n",
       "      <td>455.450000</td>\n",
       "      <td>279.631250</td>\n",
       "      <td>3315.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>184.896367</td>\n",
       "      <td>1.544380e+06</td>\n",
       "      <td>8.007785e+05</td>\n",
       "      <td>7.449864e+05</td>\n",
       "      <td>1.068583e+06</td>\n",
       "      <td>5.924144e+05</td>\n",
       "      <td>4.801816e+05</td>\n",
       "      <td>3.129818e+05</td>\n",
       "      <td>1.611216e+05</td>\n",
       "      <td>1.520336e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1038.854733</td>\n",
       "      <td>1720.535151</td>\n",
       "      <td>638.345281</td>\n",
       "      <td>362.684243</td>\n",
       "      <td>968.538748</td>\n",
       "      <td>424.108001</td>\n",
       "      <td>587.279450</td>\n",
       "      <td>1007.364839</td>\n",
       "      <td>1050.934537</td>\n",
       "      <td>4638.568719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.004000e+03</td>\n",
       "      <td>4.414000e+03</td>\n",
       "      <td>3.590000e+03</td>\n",
       "      <td>4.436000e+03</td>\n",
       "      <td>2.614000e+03</td>\n",
       "      <td>1.822000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>160.750000</td>\n",
       "      <td>8.178610e+05</td>\n",
       "      <td>4.171682e+05</td>\n",
       "      <td>4.017458e+05</td>\n",
       "      <td>4.825982e+05</td>\n",
       "      <td>2.764365e+05</td>\n",
       "      <td>2.008920e+05</td>\n",
       "      <td>8.320850e+04</td>\n",
       "      <td>4.230700e+04</td>\n",
       "      <td>4.267175e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>236.750000</td>\n",
       "      <td>589.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1024.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>320.500000</td>\n",
       "      <td>1.557367e+06</td>\n",
       "      <td>7.986815e+05</td>\n",
       "      <td>7.589200e+05</td>\n",
       "      <td>9.573465e+05</td>\n",
       "      <td>5.483525e+05</td>\n",
       "      <td>4.038590e+05</td>\n",
       "      <td>2.460160e+05</td>\n",
       "      <td>1.255485e+05</td>\n",
       "      <td>1.178550e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>1220.500000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>118.500000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>186.500000</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>2238.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>480.250000</td>\n",
       "      <td>2.583551e+06</td>\n",
       "      <td>1.338604e+06</td>\n",
       "      <td>1.264277e+06</td>\n",
       "      <td>1.602260e+06</td>\n",
       "      <td>9.188582e+05</td>\n",
       "      <td>6.641550e+05</td>\n",
       "      <td>4.477078e+05</td>\n",
       "      <td>2.284602e+05</td>\n",
       "      <td>2.140502e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>941.250000</td>\n",
       "      <td>2233.250000</td>\n",
       "      <td>296.500000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>564.500000</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>215.500000</td>\n",
       "      <td>3959.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>640.000000</td>\n",
       "      <td>1.106015e+07</td>\n",
       "      <td>5.865078e+06</td>\n",
       "      <td>5.195070e+06</td>\n",
       "      <td>8.227161e+06</td>\n",
       "      <td>4.591396e+06</td>\n",
       "      <td>3.635765e+06</td>\n",
       "      <td>2.464032e+06</td>\n",
       "      <td>1.266504e+06</td>\n",
       "      <td>1.197528e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>10334.000000</td>\n",
       "      <td>13819.000000</td>\n",
       "      <td>10835.000000</td>\n",
       "      <td>3595.000000</td>\n",
       "      <td>14430.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>7597.000000</td>\n",
       "      <td>12624.000000</td>\n",
       "      <td>18289.000000</td>\n",
       "      <td>60163.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       District code    Population          Male        Female      Literate  \\\n",
       "count     640.000000  6.400000e+02  6.400000e+02  6.400000e+02  6.400000e+02   \n",
       "mean      320.500000  1.891961e+06  9.738598e+05  9.181011e+05  1.193186e+06   \n",
       "std       184.896367  1.544380e+06  8.007785e+05  7.449864e+05  1.068583e+06   \n",
       "min         1.000000  8.004000e+03  4.414000e+03  3.590000e+03  4.436000e+03   \n",
       "25%       160.750000  8.178610e+05  4.171682e+05  4.017458e+05  4.825982e+05   \n",
       "50%       320.500000  1.557367e+06  7.986815e+05  7.589200e+05  9.573465e+05   \n",
       "75%       480.250000  2.583551e+06  1.338604e+06  1.264277e+06  1.602260e+06   \n",
       "max       640.000000  1.106015e+07  5.865078e+06  5.195070e+06  8.227161e+06   \n",
       "\n",
       "       Male_Literate  Female_Literate            SC       Male_SC  \\\n",
       "count   6.400000e+02     6.400000e+02  6.400000e+02  6.400000e+02   \n",
       "mean    6.793182e+05     5.138675e+05  3.146537e+05  1.617739e+05   \n",
       "std     5.924144e+05     4.801816e+05  3.129818e+05  1.611216e+05   \n",
       "min     2.614000e+03     1.822000e+03  0.000000e+00  0.000000e+00   \n",
       "25%     2.764365e+05     2.008920e+05  8.320850e+04  4.230700e+04   \n",
       "50%     5.483525e+05     4.038590e+05  2.460160e+05  1.255485e+05   \n",
       "75%     9.188582e+05     6.641550e+05  4.477078e+05  2.284602e+05   \n",
       "max     4.591396e+06     3.635765e+06  2.464032e+06  1.266504e+06   \n",
       "\n",
       "          Female_SC         ...          Power_Parity_Rs_90000_150000  \\\n",
       "count  6.400000e+02         ...                            640.000000   \n",
       "mean   1.528798e+05         ...                            786.046875   \n",
       "std    1.520336e+05         ...                           1038.854733   \n",
       "min    0.000000e+00         ...                              0.000000   \n",
       "25%    4.267175e+04         ...                            236.750000   \n",
       "50%    1.178550e+05         ...                            518.000000   \n",
       "75%    2.140502e+05         ...                            941.250000   \n",
       "max    1.197528e+06         ...                          10334.000000   \n",
       "\n",
       "       Power_Parity_Rs_45000_150000  Power_Parity_Rs_150000_240000  \\\n",
       "count                    640.000000                     640.000000   \n",
       "mean                    1696.456250                     294.000000   \n",
       "std                     1720.535151                     638.345281   \n",
       "min                        0.000000                       0.000000   \n",
       "25%                      589.000000                      59.000000   \n",
       "50%                     1220.500000                     149.000000   \n",
       "75%                     2233.250000                     296.500000   \n",
       "max                    13819.000000                   10835.000000   \n",
       "\n",
       "       Power_Parity_Rs_240000_330000  Power_Parity_Rs_150000_330000  \\\n",
       "count                     640.000000                     640.000000   \n",
       "mean                      215.300000                     509.300000   \n",
       "std                       362.684243                     968.538748   \n",
       "min                         0.000000                       0.000000   \n",
       "25%                        24.750000                      95.000000   \n",
       "50%                       118.500000                     278.000000   \n",
       "75%                       262.000000                     564.500000   \n",
       "max                      3595.000000                   14430.000000   \n",
       "\n",
       "       Power_Parity_Rs_330000_425000  Power_Parity_Rs_425000_545000  \\\n",
       "count                     640.000000                     640.000000   \n",
       "mean                      194.204688                     261.245313   \n",
       "std                       424.108001                     587.279450   \n",
       "min                         0.000000                       0.000000   \n",
       "25%                        19.000000                      21.000000   \n",
       "50%                        84.000000                      85.500000   \n",
       "75%                       213.250000                     293.000000   \n",
       "max                      5027.000000                    7597.000000   \n",
       "\n",
       "       Power_Parity_Rs_330000_545000  Power_Parity_Above_Rs_545000  \\\n",
       "count                     640.000000                    640.000000   \n",
       "mean                      455.450000                    279.631250   \n",
       "std                      1007.364839                   1050.934537   \n",
       "min                         0.000000                      0.000000   \n",
       "25%                        44.000000                     18.000000   \n",
       "50%                       186.500000                     60.500000   \n",
       "75%                       497.000000                    215.500000   \n",
       "max                     12624.000000                  18289.000000   \n",
       "\n",
       "       Total_Power_Parity  \n",
       "count          640.000000  \n",
       "mean          3315.412500  \n",
       "std           4638.568719  \n",
       "min              9.000000  \n",
       "25%           1024.250000  \n",
       "50%           2238.500000  \n",
       "75%           3959.000000  \n",
       "max          60163.000000  \n",
       "\n",
       "[8 rows x 116 columns]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census2011.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "District code                                                 0\n",
       "State name                                                    0\n",
       "District name                                                 0\n",
       "Population                                                    0\n",
       "Male                                                          0\n",
       "Female                                                        0\n",
       "Literate                                                      0\n",
       "Male_Literate                                                 0\n",
       "Female_Literate                                               0\n",
       "SC                                                            0\n",
       "Male_SC                                                       0\n",
       "Female_SC                                                     0\n",
       "ST                                                            0\n",
       "Male_ST                                                       0\n",
       "Female_ST                                                     0\n",
       "Workers                                                       0\n",
       "Male_Workers                                                  0\n",
       "Female_Workers                                                0\n",
       "Main_Workers                                                  0\n",
       "Marginal_Workers                                              0\n",
       "Non_Workers                                                   0\n",
       "Cultivator_Workers                                            0\n",
       "Agricultural_Workers                                          0\n",
       "Household_Workers                                             0\n",
       "Other_Workers                                                 0\n",
       "Hindus                                                        0\n",
       "Muslims                                                       0\n",
       "Christians                                                    0\n",
       "Sikhs                                                         0\n",
       "Buddhists                                                     0\n",
       "                                                             ..\n",
       "Main_source_of_drinking_water_Tubewell_Borehole_Households    0\n",
       "Household_size_1_person_Households                            0\n",
       "Household_size_2_persons_Households                           0\n",
       "Household_size_1_to_2_persons                                 0\n",
       "Household_size_3_persons_Households                           0\n",
       "Household_size_3_to_5_persons_Households                      0\n",
       "Household_size_4_persons_Households                           0\n",
       "Household_size_5_persons_Households                           0\n",
       "Household_size_6_8_persons_Households                         0\n",
       "Household_size_9_persons_and_above_Households                 0\n",
       "Location_of_drinking_water_source_Away_Households             0\n",
       "Married_couples_1_Households                                  0\n",
       "Married_couples_2_Households                                  0\n",
       "Married_couples_3_Households                                  0\n",
       "Married_couples_3_or_more_Households                          0\n",
       "Married_couples_4_Households                                  0\n",
       "Married_couples_5__Households                                 0\n",
       "Married_couples_None_Households                               0\n",
       "Power_Parity_Less_than_Rs_45000                               0\n",
       "Power_Parity_Rs_45000_90000                                   0\n",
       "Power_Parity_Rs_90000_150000                                  0\n",
       "Power_Parity_Rs_45000_150000                                  0\n",
       "Power_Parity_Rs_150000_240000                                 0\n",
       "Power_Parity_Rs_240000_330000                                 0\n",
       "Power_Parity_Rs_150000_330000                                 0\n",
       "Power_Parity_Rs_330000_425000                                 0\n",
       "Power_Parity_Rs_425000_545000                                 0\n",
       "Power_Parity_Rs_330000_545000                                 0\n",
       "Power_Parity_Above_Rs_545000                                  0\n",
       "Total_Power_Parity                                            0\n",
       "Length: 118, dtype: int64"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census2011.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                  0\n",
       "State                                       0\n",
       "District                                    0\n",
       "Persons                                     0\n",
       "Males                                       0\n",
       "Females                                     0\n",
       "Growth..1991...2001.                        0\n",
       "Rural                                       0\n",
       "Urban                                     522\n",
       "Scheduled.Caste.population                563\n",
       "Percentage...SC.to.total                  562\n",
       "Number.of.households                        3\n",
       "Household.size..per.household.              3\n",
       "Sex.ratio..females.per.1000.males.          3\n",
       "Sex.ratio..0.6.years.                       3\n",
       "Scheduled.Tribe.population                  3\n",
       "Percentage.to.total.population..ST.         3\n",
       "Persons..literate                           0\n",
       "Males..Literate                             0\n",
       "Females..Literate                           0\n",
       "Persons..literacy.rate                      0\n",
       "Males..Literatacy.Rate                      0\n",
       "Females..Literacy.Rate                      0\n",
       "Total.Educated                              3\n",
       "Data.without.level                          3\n",
       "Below.Primary                               3\n",
       "Primary                                     3\n",
       "Middle                                      3\n",
       "Matric.Higher.Secondary.Diploma             3\n",
       "Graduate.and.Above                          3\n",
       "                                         ... \n",
       "ST.2.Name                                  50\n",
       "ST.2.Population                            53\n",
       "ST.3.Name                                  50\n",
       "ST.3.Population                            52\n",
       "Imp.Town.1.Name                            21\n",
       "Imp.Town.1.Population                      14\n",
       "Imp.Town.2.Name                            97\n",
       "Imp.Town.2.Population                      64\n",
       "Imp.Town.3.Name                           142\n",
       "Imp.Town.3.Population                     108\n",
       "Total.Inhabited.Villages                   12\n",
       "Drinking.water.facilities                  12\n",
       "Safe.Drinking.water                        12\n",
       "Electricity..Power.Supply.                 12\n",
       "Electricity..domestic.                     12\n",
       "Electricity..Agriculture.                 208\n",
       "Primary.school                             12\n",
       "Middle.schools                             12\n",
       "Secondary.Sr.Secondary.schools             12\n",
       "College                                    52\n",
       "Medical.facility                           12\n",
       "Primary.Health.Centre                      12\n",
       "Primary.Health.Sub.Centre                  12\n",
       "Post..telegraph.and.telephone.facility     12\n",
       "Bus.services                               12\n",
       "Paved.approach.road                        12\n",
       "Mud.approach.road                          12\n",
       "Permanent.House                             0\n",
       "Semi.permanent.House                        0\n",
       "Temporary.House                             0\n",
       "Length: 82, dtype: int64"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop200.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590, 82)"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop200.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 590 entries, 0 to 589\n",
      "Data columns (total 82 columns):\n",
      "Unnamed: 0                                590 non-null int64\n",
      "State                                     590 non-null object\n",
      "District                                  590 non-null object\n",
      "Persons                                   590 non-null int64\n",
      "Males                                     590 non-null int64\n",
      "Females                                   590 non-null int64\n",
      "Growth..1991...2001.                      590 non-null float64\n",
      "Rural                                     590 non-null object\n",
      "Urban                                     68 non-null object\n",
      "Scheduled.Caste.population                27 non-null object\n",
      "Percentage...SC.to.total                  28 non-null object\n",
      "Number.of.households                      587 non-null float64\n",
      "Household.size..per.household.            587 non-null float64\n",
      "Sex.ratio..females.per.1000.males.        587 non-null float64\n",
      "Sex.ratio..0.6.years.                     587 non-null float64\n",
      "Scheduled.Tribe.population                587 non-null object\n",
      "Percentage.to.total.population..ST.       587 non-null object\n",
      "Persons..literate                         590 non-null int64\n",
      "Males..Literate                           590 non-null int64\n",
      "Females..Literate                         590 non-null int64\n",
      "Persons..literacy.rate                    590 non-null float64\n",
      "Males..Literatacy.Rate                    590 non-null float64\n",
      "Females..Literacy.Rate                    590 non-null float64\n",
      "Total.Educated                            587 non-null float64\n",
      "Data.without.level                        587 non-null float64\n",
      "Below.Primary                             587 non-null float64\n",
      "Primary                                   587 non-null float64\n",
      "Middle                                    587 non-null float64\n",
      "Matric.Higher.Secondary.Diploma           587 non-null float64\n",
      "Graduate.and.Above                        587 non-null float64\n",
      "X0...4.years                              587 non-null float64\n",
      "X5...14.years                             587 non-null float64\n",
      "X15...59.years                            587 non-null float64\n",
      "X60.years.and.above..Incl..A.N.S..        587 non-null float64\n",
      "Total.workers                             590 non-null int64\n",
      "Main.workers                              590 non-null int64\n",
      "Marginal.workers                          590 non-null int64\n",
      "Non.workers                               590 non-null int64\n",
      "SC.1.Name                                 539 non-null object\n",
      "SC.1.Population                           577 non-null float64\n",
      "SC.2.Name                                 526 non-null object\n",
      "SC.2.Population                           577 non-null float64\n",
      "SC.3.Name                                 524 non-null object\n",
      "SC.3.Population                           577 non-null float64\n",
      "Religeon.1.Name                           537 non-null object\n",
      "Religeon.1.Population                     590 non-null int64\n",
      "Religeon.2.Name                           537 non-null object\n",
      "Religeon.2.Population                     590 non-null int64\n",
      "Religeon.3.Name                           537 non-null object\n",
      "Religeon.3.Population                     590 non-null int64\n",
      "ST.1.Name                                 590 non-null object\n",
      "ST.1.Population                           539 non-null object\n",
      "ST.2.Name                                 540 non-null object\n",
      "ST.2.Population                           537 non-null object\n",
      "ST.3.Name                                 540 non-null object\n",
      "ST.3.Population                           538 non-null object\n",
      "Imp.Town.1.Name                           569 non-null object\n",
      "Imp.Town.1.Population                     576 non-null float64\n",
      "Imp.Town.2.Name                           493 non-null object\n",
      "Imp.Town.2.Population                     526 non-null float64\n",
      "Imp.Town.3.Name                           448 non-null object\n",
      "Imp.Town.3.Population                     482 non-null float64\n",
      "Total.Inhabited.Villages                  578 non-null float64\n",
      "Drinking.water.facilities                 578 non-null float64\n",
      "Safe.Drinking.water                       578 non-null float64\n",
      "Electricity..Power.Supply.                578 non-null float64\n",
      "Electricity..domestic.                    578 non-null object\n",
      "Electricity..Agriculture.                 382 non-null object\n",
      "Primary.school                            578 non-null float64\n",
      "Middle.schools                            578 non-null object\n",
      "Secondary.Sr.Secondary.schools            578 non-null object\n",
      "College                                   538 non-null object\n",
      "Medical.facility                          578 non-null object\n",
      "Primary.Health.Centre                     578 non-null object\n",
      "Primary.Health.Sub.Centre                 578 non-null object\n",
      "Post..telegraph.and.telephone.facility    578 non-null float64\n",
      "Bus.services                              578 non-null object\n",
      "Paved.approach.road                       578 non-null object\n",
      "Mud.approach.road                         578 non-null object\n",
      "Permanent.House                           590 non-null float64\n",
      "Semi.permanent.House                      590 non-null float64\n",
      "Temporary.House                           590 non-null float64\n",
      "dtypes: float64(34), int64(14), object(34)\n",
      "memory usage: 378.0+ KB\n"
     ]
    }
   ],
   "source": [
    "pop200.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Persons</th>\n",
       "      <th>Males</th>\n",
       "      <th>Females</th>\n",
       "      <th>Growth..1991...2001.</th>\n",
       "      <th>Number.of.households</th>\n",
       "      <th>Household.size..per.household.</th>\n",
       "      <th>Sex.ratio..females.per.1000.males.</th>\n",
       "      <th>Sex.ratio..0.6.years.</th>\n",
       "      <th>Persons..literate</th>\n",
       "      <th>...</th>\n",
       "      <th>Imp.Town.3.Population</th>\n",
       "      <th>Total.Inhabited.Villages</th>\n",
       "      <th>Drinking.water.facilities</th>\n",
       "      <th>Safe.Drinking.water</th>\n",
       "      <th>Electricity..Power.Supply.</th>\n",
       "      <th>Primary.school</th>\n",
       "      <th>Post..telegraph.and.telephone.facility</th>\n",
       "      <th>Permanent.House</th>\n",
       "      <th>Semi.permanent.House</th>\n",
       "      <th>Temporary.House</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>590.000000</td>\n",
       "      <td>5.900000e+02</td>\n",
       "      <td>5.900000e+02</td>\n",
       "      <td>5.900000e+02</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>5.870000e+02</td>\n",
       "      <td>587.000000</td>\n",
       "      <td>587.000000</td>\n",
       "      <td>587.000000</td>\n",
       "      <td>5.900000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>578.000000</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>590.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>295.500000</td>\n",
       "      <td>1.732902e+06</td>\n",
       "      <td>8.966605e+05</td>\n",
       "      <td>8.362419e+05</td>\n",
       "      <td>22.493119</td>\n",
       "      <td>3.258233e+05</td>\n",
       "      <td>5.436116</td>\n",
       "      <td>934.800681</td>\n",
       "      <td>929.388416</td>\n",
       "      <td>9.442850e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>41223.562241</td>\n",
       "      <td>1016.451557</td>\n",
       "      <td>1009.671280</td>\n",
       "      <td>992.044983</td>\n",
       "      <td>774.759516</td>\n",
       "      <td>796.794118</td>\n",
       "      <td>419.726644</td>\n",
       "      <td>47.624644</td>\n",
       "      <td>32.856000</td>\n",
       "      <td>19.490051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>170.462606</td>\n",
       "      <td>1.329998e+06</td>\n",
       "      <td>6.934142e+05</td>\n",
       "      <td>6.381679e+05</td>\n",
       "      <td>11.294956</td>\n",
       "      <td>2.666372e+05</td>\n",
       "      <td>0.846952</td>\n",
       "      <td>62.718746</td>\n",
       "      <td>47.554772</td>\n",
       "      <td>8.437970e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>52626.613978</td>\n",
       "      <td>816.524396</td>\n",
       "      <td>809.966443</td>\n",
       "      <td>801.088455</td>\n",
       "      <td>611.197664</td>\n",
       "      <td>555.064067</td>\n",
       "      <td>331.545869</td>\n",
       "      <td>24.603409</td>\n",
       "      <td>21.587237</td>\n",
       "      <td>20.760061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.139400e+04</td>\n",
       "      <td>1.589300e+04</td>\n",
       "      <td>1.478300e+04</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>6.054000e+03</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>766.000000</td>\n",
       "      <td>1.342400e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>148.250000</td>\n",
       "      <td>8.127185e+05</td>\n",
       "      <td>4.207508e+05</td>\n",
       "      <td>3.890438e+05</td>\n",
       "      <td>15.352500</td>\n",
       "      <td>1.559300e+05</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>895.000000</td>\n",
       "      <td>912.000000</td>\n",
       "      <td>4.144205e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>17390.250000</td>\n",
       "      <td>467.750000</td>\n",
       "      <td>466.250000</td>\n",
       "      <td>442.750000</td>\n",
       "      <td>311.500000</td>\n",
       "      <td>397.500000</td>\n",
       "      <td>172.500000</td>\n",
       "      <td>28.225000</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>295.500000</td>\n",
       "      <td>1.487712e+06</td>\n",
       "      <td>7.706160e+05</td>\n",
       "      <td>7.133320e+05</td>\n",
       "      <td>21.830000</td>\n",
       "      <td>2.686090e+05</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>938.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>7.693050e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>29149.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>886.500000</td>\n",
       "      <td>881.500000</td>\n",
       "      <td>645.500000</td>\n",
       "      <td>758.500000</td>\n",
       "      <td>354.500000</td>\n",
       "      <td>47.550000</td>\n",
       "      <td>28.850000</td>\n",
       "      <td>10.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>442.750000</td>\n",
       "      <td>2.395986e+06</td>\n",
       "      <td>1.248934e+06</td>\n",
       "      <td>1.142946e+06</td>\n",
       "      <td>27.147500</td>\n",
       "      <td>4.337020e+05</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>974.500000</td>\n",
       "      <td>962.000000</td>\n",
       "      <td>1.220172e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>47965.000000</td>\n",
       "      <td>1386.000000</td>\n",
       "      <td>1376.500000</td>\n",
       "      <td>1368.750000</td>\n",
       "      <td>1086.750000</td>\n",
       "      <td>1133.750000</td>\n",
       "      <td>580.750000</td>\n",
       "      <td>66.300000</td>\n",
       "      <td>47.175000</td>\n",
       "      <td>30.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>590.000000</td>\n",
       "      <td>9.610788e+06</td>\n",
       "      <td>4.916370e+06</td>\n",
       "      <td>4.694418e+06</td>\n",
       "      <td>95.010000</td>\n",
       "      <td>1.838426e+06</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1147.000000</td>\n",
       "      <td>1035.000000</td>\n",
       "      <td>6.617264e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>704002.000000</td>\n",
       "      <td>10548.000000</td>\n",
       "      <td>10475.000000</td>\n",
       "      <td>10455.000000</td>\n",
       "      <td>4835.000000</td>\n",
       "      <td>6133.000000</td>\n",
       "      <td>2346.000000</td>\n",
       "      <td>98.600000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>85.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       Persons         Males       Females  \\\n",
       "count  590.000000  5.900000e+02  5.900000e+02  5.900000e+02   \n",
       "mean   295.500000  1.732902e+06  8.966605e+05  8.362419e+05   \n",
       "std    170.462606  1.329998e+06  6.934142e+05  6.381679e+05   \n",
       "min      1.000000  3.139400e+04  1.589300e+04  1.478300e+04   \n",
       "25%    148.250000  8.127185e+05  4.207508e+05  3.890438e+05   \n",
       "50%    295.500000  1.487712e+06  7.706160e+05  7.133320e+05   \n",
       "75%    442.750000  2.395986e+06  1.248934e+06  1.142946e+06   \n",
       "max    590.000000  9.610788e+06  4.916370e+06  4.694418e+06   \n",
       "\n",
       "       Growth..1991...2001.  Number.of.households  \\\n",
       "count            590.000000          5.870000e+02   \n",
       "mean              22.493119          3.258233e+05   \n",
       "std               11.294956          2.666372e+05   \n",
       "min               -3.500000          6.054000e+03   \n",
       "25%               15.352500          1.559300e+05   \n",
       "50%               21.830000          2.686090e+05   \n",
       "75%               27.147500          4.337020e+05   \n",
       "max               95.010000          1.838426e+06   \n",
       "\n",
       "       Household.size..per.household.  Sex.ratio..females.per.1000.males.  \\\n",
       "count                      587.000000                          587.000000   \n",
       "mean                         5.436116                          934.800681   \n",
       "std                          0.846952                           62.718746   \n",
       "min                          4.000000                          591.000000   \n",
       "25%                          5.000000                          895.000000   \n",
       "50%                          5.000000                          938.000000   \n",
       "75%                          6.000000                          974.500000   \n",
       "max                          8.000000                         1147.000000   \n",
       "\n",
       "       Sex.ratio..0.6.years.  Persons..literate       ...         \\\n",
       "count             587.000000       5.900000e+02       ...          \n",
       "mean              929.388416       9.442850e+05       ...          \n",
       "std                47.554772       8.437970e+05       ...          \n",
       "min               766.000000       1.342400e+04       ...          \n",
       "25%               912.000000       4.144205e+05       ...          \n",
       "50%               942.000000       7.693050e+05       ...          \n",
       "75%               962.000000       1.220172e+06       ...          \n",
       "max              1035.000000       6.617264e+06       ...          \n",
       "\n",
       "       Imp.Town.3.Population  Total.Inhabited.Villages  \\\n",
       "count             482.000000                578.000000   \n",
       "mean            41223.562241               1016.451557   \n",
       "std             52626.613978                816.524396   \n",
       "min               605.000000                  2.000000   \n",
       "25%             17390.250000                467.750000   \n",
       "50%             29149.000000                891.000000   \n",
       "75%             47965.000000               1386.000000   \n",
       "max            704002.000000              10548.000000   \n",
       "\n",
       "       Drinking.water.facilities  Safe.Drinking.water  \\\n",
       "count                 578.000000           578.000000   \n",
       "mean                 1009.671280           992.044983   \n",
       "std                   809.966443           801.088455   \n",
       "min                     2.000000             1.000000   \n",
       "25%                   466.250000           442.750000   \n",
       "50%                   886.500000           881.500000   \n",
       "75%                  1376.500000          1368.750000   \n",
       "max                 10475.000000         10455.000000   \n",
       "\n",
       "       Electricity..Power.Supply.  Primary.school  \\\n",
       "count                  578.000000      578.000000   \n",
       "mean                   774.759516      796.794118   \n",
       "std                    611.197664      555.064067   \n",
       "min                      2.000000        1.000000   \n",
       "25%                    311.500000      397.500000   \n",
       "50%                    645.500000      758.500000   \n",
       "75%                   1086.750000     1133.750000   \n",
       "max                   4835.000000     6133.000000   \n",
       "\n",
       "       Post..telegraph.and.telephone.facility  Permanent.House  \\\n",
       "count                              578.000000       590.000000   \n",
       "mean                               419.726644        47.624644   \n",
       "std                                331.545869        24.603409   \n",
       "min                                  2.000000         1.600000   \n",
       "25%                                172.500000        28.225000   \n",
       "50%                                354.500000        47.550000   \n",
       "75%                                580.750000        66.300000   \n",
       "max                               2346.000000        98.600000   \n",
       "\n",
       "       Semi.permanent.House  Temporary.House  \n",
       "count            590.000000       590.000000  \n",
       "mean              32.856000        19.490051  \n",
       "std               21.587237        20.760061  \n",
       "min                1.000000         0.100000  \n",
       "25%               14.600000         3.400000  \n",
       "50%               28.850000        10.750000  \n",
       "75%               47.175000        30.175000  \n",
       "max               95.000000        85.600000  \n",
       "\n",
       "[8 rows x 48 columns]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop200.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[0.11273534]\n",
      "[[0.95452611]]\n",
      "[[0.74562765]]\n"
     ]
    }
   ],
   "source": [
    "# For INDIA\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 1]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5 entries, States to 2041\n",
      "Data columns (total 24 columns):\n",
      "0     4 non-null object\n",
      "1     5 non-null object\n",
      "2     5 non-null object\n",
      "3     5 non-null object\n",
      "4     5 non-null object\n",
      "5     5 non-null object\n",
      "6     5 non-null object\n",
      "7     5 non-null object\n",
      "8     5 non-null object\n",
      "9     5 non-null object\n",
      "10    5 non-null object\n",
      "11    5 non-null object\n",
      "12    5 non-null object\n",
      "13    5 non-null object\n",
      "14    5 non-null object\n",
      "15    5 non-null object\n",
      "16    5 non-null object\n",
      "17    5 non-null object\n",
      "18    5 non-null object\n",
      "19    5 non-null object\n",
      "20    5 non-null object\n",
      "21    5 non-null object\n",
      "22    5 non-null object\n",
      "23    5 non-null object\n",
      "dtypes: object(24)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "rd.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[-0.23251091]\n",
      "[[0.78203372]]\n",
      "[[0.28601144]]\n"
     ]
    }
   ],
   "source": [
    "# FOR ALL DIFFERENT STATES\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 2]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[0.01244156]\n",
      "[[0.91677391]]\n",
      "[[0.62030252]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 3]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[0.60912248]\n",
      "[[1.11959518]]\n",
      "[[1.35146276]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 4]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[0.02308366]\n",
      "[[1.24576999]]\n",
      "[[0.84908333]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 5]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[-0.26780421]\n",
      "[[1.33852371]]\n",
      "[[0.6196952]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 6]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[0.01721192]\n",
      "[[1.08971878]]\n",
      "[[0.73974285]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 7]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[-0.02632082]\n",
      "[[1.13744778]]\n",
      "[[0.72785651]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 8]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[-0.0890924]\n",
      "[[0.77244484]]\n",
      "[[0.42307212]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 9]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[-0.22291978]\n",
      "[[1.39409624]]\n",
      "[[0.70142664]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 10]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[0.3863688]\n",
      "[[1.042981]]\n",
      "[[1.07791054]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 11]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[-0.32069128]\n",
      "[[1.0687094]]\n",
      "[[0.38790952]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 12]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[0.22520961]\n",
      "[[0.20738947]]\n",
      "[[0.36271785]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 13]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[0.27927605]\n",
      "[[1.01169317]]\n",
      "[[0.9500726]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 14]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[-0.29359583]\n",
      "[[1.06513242]]\n",
      "[[0.41263327]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 15]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[0.0805418]\n",
      "[[0.74743829]]\n",
      "[[0.57612588]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 16]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[-0.2469696]\n",
      "[[0.93522981]]\n",
      "[[0.37312842]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 17]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[0.39390889]\n",
      "[[1.00411902]]\n",
      "[[1.05968346]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 18]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[-0.55591965]\n",
      "[[1.18460576]]\n",
      "[[0.22952548]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 19]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[-0.27662214]\n",
      "[[1.14133575]]\n",
      "[[0.48013308]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 20]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[0.42740626]\n",
      "[[0.93423858]]\n",
      "[[1.04684706]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 21]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[0.17538021]\n",
      "[[0.99955082]]\n",
      "[[0.83812586]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 22]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     1.76136\n",
      "2021    0.998261\n",
      "2031    0.663043\n",
      "2041    0.395652\n",
      "Name: 0, dtype: object\n",
      "[-0.21023995]\n",
      "[[0.90664628]]\n",
      "[[0.39090595]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=popgro.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 23]\n",
    "\n",
    "print (x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>States</th>\n",
       "      <th>2011</th>\n",
       "      <th>2021</th>\n",
       "      <th>2031</th>\n",
       "      <th>2041</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.761364</td>\n",
       "      <td>0.998261</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.395652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assam</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bihar</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>1.340000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1.930000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Haryana</td>\n",
       "      <td>1.990000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>2.240000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kerala</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>2.030000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Odisha</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Punjab</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>2.130000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Telangana</td>\n",
       "      <td>1.761364</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              States      2011      2021      2031      2041\n",
       "0                NaN  1.761364  0.998261  0.663043  0.395652\n",
       "1              INDIA  1.770000  1.120000  0.720000  0.460000\n",
       "2     Andhra Pradesh  1.100000  0.650000  0.310000  0.020000\n",
       "3              Assam  1.710000  0.740000  0.770000  0.480000\n",
       "4              Bihar  2.540000  1.820000  1.340000  1.000000\n",
       "5       Chhattisgarh  2.260000  1.170000  0.760000  0.570000\n",
       "6              Delhi  2.120000  1.000000  0.620000  0.300000\n",
       "7            Gujarat  1.930000  1.120000  0.710000  0.440000\n",
       "8            Haryana  1.990000  1.080000  0.700000  0.440000\n",
       "9   Himachal Pradesh  1.290000  0.640000  0.570000  0.240000\n",
       "10   Jammu & Kashmir  2.360000  0.880000  0.820000  0.490000\n",
       "11         Jharkhand  2.240000  1.390000  0.970000  0.820000\n",
       "12         Karnataka  1.560000  0.750000  0.360000  0.100000\n",
       "13            Kerala  0.490000  0.660000  0.450000  0.180000\n",
       "14    Madhya Pradesh  2.030000  1.360000  0.810000  0.640000\n",
       "15       Maharashtra  1.600000  0.730000  0.420000  0.150000\n",
       "16            Odisha  1.400000  0.820000  0.630000  0.380000\n",
       "17            Punjab  1.390000  0.710000  0.420000  0.110000\n",
       "18         Rajasthan  2.130000  1.470000  0.960000  0.750000\n",
       "19        Tamil Nadu  1.560000  0.560000  0.250000 -0.050000\n",
       "20         Telangana  1.761364  0.800000  0.530000  0.210000\n",
       "21     Uttar Pradesh  2.020000  1.480000  0.930000  0.730000\n",
       "22       Uttarakhand  1.880000  1.300000  0.700000  0.500000\n",
       "23       West Bengal  1.380000  0.710000  0.500000  0.140000"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popgro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting the positions and width for the bars\n",
    "pos = list(range(len(popgro['2011']))) \n",
    "width = 0.20\n",
    "    \n",
    "# Plotting the bars\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "\n",
    "# Create a bar with pre_score data,\n",
    "# in position pos,\n",
    "plt.bar(pos, \n",
    "        #using df['pre_score'] data,\n",
    "        popgro['2011'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#EE3224', \n",
    "        # with label the first value in first_name\n",
    "        label=popgro['States'][0]) \n",
    "\n",
    "# Create a bar with mid_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width for p in pos], \n",
    "        #using df['mid_score'] data,\n",
    "        popgro['2021'],\n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#F78F1E', \n",
    "        # with label the second value in first_name\n",
    "        label=popgro['States'][1]) \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width*2 for p in pos], \n",
    "        #using df['post_score'] data,\n",
    "        popgro['2031'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#FFC222', \n",
    "        # with label the third value in first_name\n",
    "        label=popgro['States'][2]) \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width*3 for p in pos], \n",
    "        #using df['post_score'] data,\n",
    "        popgro['2041'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='blue', \n",
    "        # with label the third value in first_name\n",
    "        label=popgro['States'][3]) \n",
    "\n",
    "# Set the y axis label\n",
    "ax.set_ylabel('Growth')\n",
    "\n",
    "# Set the chart's title\n",
    "ax.set_title('Growth prediction')\n",
    "\n",
    "# Set the position of the x ticks\n",
    "ax.set_xticks([p + 1.5 * width for p in pos])\n",
    "\n",
    "# Set the labels for the x ticks\n",
    "ax.set_xticklabels(popgro['States'])\n",
    "\n",
    "# Setting the x-axis and y-axis limits\n",
    "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "plt.ylim([0, max(popgro['2011'] + popgro['2021'] + popgro['2031'] + popgro['2041'])] )\n",
    "\n",
    "# Adding the legend and showing the plot\n",
    "plt.legend(['2011', '2021', '2031','2041'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                        State          1951  1961  1971  1981  1991  2001  2011\n",
       "0                       India   946.000000   941   930   934   927   933   943\n",
       "1   Andaman & Nicobar Islands   625.000000   617   644   760   818   846   876\n",
       "2              Andhra Pradesh   986.000000   981   977   975   972   978   993\n",
       "3           Arunachal Pradesh   944.628571   894   861   862   859   893   938\n",
       "4                       Assam   868.000000   869   896   910   923   935   958\n",
       "5                       Bihar  1000.000000  1005   957   948   907   919   918\n",
       "6                  Chandigarh   781.000000   652   749   769   790   777   818\n",
       "7                Chhattisgarh  1024.000000  1008   998   996   985   989   991\n",
       "8        Dadra & Nagar Haveli   946.000000   963  1007   974   952   812   774\n",
       "9                 Daman & Diu  1125.000000  1169  1099  1062   969   710   618\n",
       "10                      Delhi   768.000000   785   801   808   827   821   868\n",
       "11                        Goa  1128.000000  1066   981   975   967   961   973\n",
       "12                    Gujarat   952.000000   940   934   942   934   920   919\n",
       "13                    Haryana   871.000000   868   867   870   865   861   879\n",
       "14           Himachal Pradesh   912.000000   938   958   973   976   968   972\n",
       "15            Jammu & Kashmir   873.000000   878   878   892   896   892   889\n",
       "16                  Jharkhand   961.000000   960   945   940   922   941   948\n",
       "17                  Karnataka   966.000000   959   957   963   960   965   973\n",
       "18                     Kerala  1028.000000  1022  1016  1032  1036  1058  1084\n",
       "19                Lakshadweep  1043.000000  1020   978   975   943   948   946\n",
       "20             Madhya Pradesh   945.000000   932   920   921   912   919   931\n",
       "21                Maharashtra   941.000000   936   930   937   934   922   929\n",
       "22                    Manipur  1036.000000  1015   980   971   958   974   992\n",
       "23                  Meghalaya   949.000000   937   942   954   955   972   989\n",
       "24                    Mizoram  1041.000000  1009   946   919   921   935   976\n",
       "25                   Nagaland   999.000000   933   871   863   886   900   931\n",
       "26                     Odisha  1022.000000  1001   988   981   971   972   979\n",
       "27                 Puducherry  1030.000000  1013   989   985   979  1001  1037\n",
       "28                     Punjab   844.000000   854   865   879   882   876   895\n",
       "29                  Rajasthan   921.000000   908   911   919   910   921   928\n",
       "30                     Sikkim   907.000000   904   863   835   878   875   890\n",
       "31                 Tamil Nadu  1007.000000   992   978   977   974   987   996\n",
       "32                    Tripura   904.000000   932   943   946   945   948   960\n",
       "33              Uttar Pradesh   908.000000   907   876   882   876   898   912\n",
       "34                Uttarakhand   940.000000   947   940   936   936   962   963\n",
       "35                West Bengal   865.000000   878   891   911   917   934   950>"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexr.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    946\n",
      "1961    941\n",
      "1971    930\n",
      "1981    934\n",
      "1991    927\n",
      "2001    933\n",
      "2011    943\n",
      "Name: 0, dtype: object\n",
      "[932.28571429]\n",
      "[931.28571429]\n",
      "[930.28571429]\n",
      "[929.28571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],0]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    625\n",
      "1961    617\n",
      "1971    644\n",
      "1981    760\n",
      "1991    818\n",
      "2001    846\n",
      "2011    876\n",
      "Name: 1, dtype: object\n",
      "[938.71428571]\n",
      "[988.17857143]\n",
      "[1037.64285714]\n",
      "[1087.10714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],1]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    986\n",
      "1961    981\n",
      "1971    977\n",
      "1981    975\n",
      "1991    972\n",
      "2001    978\n",
      "2011    993\n",
      "Name: 2, dtype: object\n",
      "[981.71428571]\n",
      "[982.07142857]\n",
      "[982.42857143]\n",
      "[982.78571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],2]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    944.629\n",
      "1961        894\n",
      "1971        861\n",
      "1981        862\n",
      "1991        859\n",
      "2001        893\n",
      "2011        938\n",
      "Name: 3, dtype: object\n",
      "[889.67755102]\n",
      "[888.8244898]\n",
      "[887.97142857]\n",
      "[887.11836735]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],3]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    868\n",
      "1961    869\n",
      "1971    896\n",
      "1981    910\n",
      "1991    923\n",
      "2001    935\n",
      "2011    958\n",
      "Name: 4, dtype: object\n",
      "[969.71428571]\n",
      "[985.03571429]\n",
      "[1000.35714286]\n",
      "[1015.67857143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],4]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    1000\n",
      "1961    1005\n",
      "1971     957\n",
      "1981     948\n",
      "1991     907\n",
      "2001     919\n",
      "2011     918\n",
      "Name: 5, dtype: object\n",
      "[883.71428571]\n",
      "[867.]\n",
      "[850.28571429]\n",
      "[833.57142857]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],5]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    781\n",
      "1961    652\n",
      "1971    749\n",
      "1981    769\n",
      "1991    790\n",
      "2001    777\n",
      "2011    818\n",
      "Name: 6, dtype: object\n",
      "[819.71428571]\n",
      "[834.07142857]\n",
      "[848.42857143]\n",
      "[862.78571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],6]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    1024\n",
      "1961    1008\n",
      "1971     998\n",
      "1981     996\n",
      "1991     985\n",
      "2001     989\n",
      "2011     991\n",
      "Name: 7, dtype: object\n",
      "[977.28571429]\n",
      "[971.92857143]\n",
      "[966.57142857]\n",
      "[961.21428571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],7]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951     946\n",
      "1961     963\n",
      "1971    1007\n",
      "1981     974\n",
      "1991     952\n",
      "2001     812\n",
      "2011     774\n",
      "Name: 8, dtype: object\n",
      "[793.57142857]\n",
      "[762.39285714]\n",
      "[731.21428571]\n",
      "[700.03571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],8]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    1125\n",
      "1961    1169\n",
      "1971    1099\n",
      "1981    1062\n",
      "1991     969\n",
      "2001     710\n",
      "2011     618\n",
      "Name: 9, dtype: object\n",
      "[597.57142857]\n",
      "[505.82142857]\n",
      "[414.07142857]\n",
      "[322.32142857]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],9]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    768\n",
      "1961    785\n",
      "1971    801\n",
      "1981    808\n",
      "1991    827\n",
      "2001    821\n",
      "2011    868\n",
      "Name: 10, dtype: object\n",
      "[868.]\n",
      "[882.21428571]\n",
      "[896.42857143]\n",
      "[910.64285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],10]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    1128\n",
      "1961    1066\n",
      "1971     981\n",
      "1981     975\n",
      "1991     967\n",
      "2001     961\n",
      "2011     973\n",
      "Name: 11, dtype: object\n",
      "[908.85714286]\n",
      "[884.25]\n",
      "[859.64285714]\n",
      "[835.03571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],11]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    952\n",
      "1961    940\n",
      "1971    934\n",
      "1981    942\n",
      "1991    934\n",
      "2001    920\n",
      "2011    919\n",
      "Name: 12, dtype: object\n",
      "[914.57142857]\n",
      "[909.60714286]\n",
      "[904.64285714]\n",
      "[899.67857143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],12]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    871\n",
      "1961    868\n",
      "1971    867\n",
      "1981    870\n",
      "1991    865\n",
      "2001    861\n",
      "2011    879\n",
      "Name: 13, dtype: object\n",
      "[869.85714286]\n",
      "[870.14285714]\n",
      "[870.42857143]\n",
      "[870.71428571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],13]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    912\n",
      "1961    938\n",
      "1971    958\n",
      "1981    973\n",
      "1991    976\n",
      "2001    968\n",
      "2011    972\n",
      "Name: 14, dtype: object\n",
      "[993.57142857]\n",
      "[1002.78571429]\n",
      "[1012.]\n",
      "[1021.21428571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],14]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    873\n",
      "1961    878\n",
      "1971    878\n",
      "1981    892\n",
      "1991    896\n",
      "2001    892\n",
      "2011    889\n",
      "Name: 15, dtype: object\n",
      "[898.85714286]\n",
      "[902.21428571]\n",
      "[905.57142857]\n",
      "[908.92857143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],15]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    961\n",
      "1961    960\n",
      "1971    945\n",
      "1981    940\n",
      "1991    922\n",
      "2001    941\n",
      "2011    948\n",
      "Name: 16, dtype: object\n",
      "[931.]\n",
      "[927.42857143]\n",
      "[923.85714286]\n",
      "[920.28571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],16]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    966\n",
      "1961    959\n",
      "1971    957\n",
      "1981    963\n",
      "1991    960\n",
      "2001    965\n",
      "2011    973\n",
      "Name: 17, dtype: object\n",
      "[968.42857143]\n",
      "[969.71428571]\n",
      "[971.]\n",
      "[972.28571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],17]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    1028\n",
      "1961    1022\n",
      "1971    1016\n",
      "1981    1032\n",
      "1991    1036\n",
      "2001    1058\n",
      "2011    1084\n",
      "Name: 18, dtype: object\n",
      "[1076.57142857]\n",
      "[1085.85714286]\n",
      "[1095.14285714]\n",
      "[1104.42857143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],18]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    1043\n",
      "1961    1020\n",
      "1971     978\n",
      "1981     975\n",
      "1991     943\n",
      "2001     948\n",
      "2011     946\n",
      "Name: 19, dtype: object\n",
      "[911.85714286]\n",
      "[895.07142857]\n",
      "[878.28571429]\n",
      "[861.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],19]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    945\n",
      "1961    932\n",
      "1971    920\n",
      "1981    921\n",
      "1991    912\n",
      "2001    919\n",
      "2011    931\n",
      "Name: 20, dtype: object\n",
      "[914.85714286]\n",
      "[912.14285714]\n",
      "[909.42857143]\n",
      "[906.71428571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],20]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    941\n",
      "1961    936\n",
      "1971    930\n",
      "1981    937\n",
      "1991    934\n",
      "2001    922\n",
      "2011    929\n",
      "Name: 21, dtype: object\n",
      "[924.14285714]\n",
      "[922.]\n",
      "[919.85714286]\n",
      "[917.71428571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],21]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    1036\n",
      "1961    1015\n",
      "1971     980\n",
      "1981     971\n",
      "1991     958\n",
      "2001     974\n",
      "2011     992\n",
      "Name: 22, dtype: object\n",
      "[955.71428571]\n",
      "[947.28571429]\n",
      "[938.85714286]\n",
      "[930.42857143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],22]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    949\n",
      "1961    937\n",
      "1971    942\n",
      "1981    954\n",
      "1991    955\n",
      "2001    972\n",
      "2011    989\n",
      "Name: 23, dtype: object\n",
      "[985.85714286]\n",
      "[993.10714286]\n",
      "[1000.35714286]\n",
      "[1007.60714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],23]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    1041\n",
      "1961    1009\n",
      "1971     946\n",
      "1981     919\n",
      "1991     921\n",
      "2001     935\n",
      "2011     976\n",
      "Name: 24, dtype: object\n",
      "[911.28571429]\n",
      "[898.14285714]\n",
      "[885.]\n",
      "[871.85714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],24]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    999\n",
      "1961    933\n",
      "1971    871\n",
      "1981    863\n",
      "1991    886\n",
      "2001    900\n",
      "2011    931\n",
      "Name: 25, dtype: object\n",
      "[875.42857143]\n",
      "[866.32142857]\n",
      "[857.21428571]\n",
      "[848.10714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],25]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    1022\n",
      "1961    1001\n",
      "1971     988\n",
      "1981     981\n",
      "1991     971\n",
      "2001     972\n",
      "2011     979\n",
      "Name: 26, dtype: object\n",
      "[958.57142857]\n",
      "[951.28571429]\n",
      "[944.]\n",
      "[936.71428571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],26]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    1030\n",
      "1961    1013\n",
      "1971     989\n",
      "1981     985\n",
      "1991     979\n",
      "2001    1001\n",
      "2011    1037\n",
      "Name: 27, dtype: object\n",
      "[1003.]\n",
      "[1002.53571429]\n",
      "[1002.07142857]\n",
      "[1001.60714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],27]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    844\n",
      "1961    854\n",
      "1971    865\n",
      "1981    879\n",
      "1991    882\n",
      "2001    876\n",
      "2011    895\n",
      "Name: 28, dtype: object\n",
      "[901.28571429]\n",
      "[908.92857143]\n",
      "[916.57142857]\n",
      "[924.21428571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],28]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    921\n",
      "1961    908\n",
      "1971    911\n",
      "1981    919\n",
      "1991    910\n",
      "2001    921\n",
      "2011    928\n",
      "Name: 29, dtype: object\n",
      "[923.42857143]\n",
      "[925.07142857]\n",
      "[926.71428571]\n",
      "[928.35714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],29]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    907\n",
      "1961    904\n",
      "1971    863\n",
      "1981    835\n",
      "1991    878\n",
      "2001    875\n",
      "2011    890\n",
      "Name: 30, dtype: object\n",
      "[865.42857143]\n",
      "[862.07142857]\n",
      "[858.71428571]\n",
      "[855.35714286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],30]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    1007\n",
      "1961     992\n",
      "1971     978\n",
      "1981     977\n",
      "1991     974\n",
      "2001     987\n",
      "2011     996\n",
      "Name: 31, dtype: object\n",
      "[980.57142857]\n",
      "[978.89285714]\n",
      "[977.21428571]\n",
      "[975.53571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],31]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    904\n",
      "1961    932\n",
      "1971    943\n",
      "1981    946\n",
      "1991    945\n",
      "2001    948\n",
      "2011    960\n",
      "Name: 32, dtype: object\n",
      "[968.57142857]\n",
      "[975.78571429]\n",
      "[983.]\n",
      "[990.21428571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],32]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    908\n",
      "1961    907\n",
      "1971    876\n",
      "1981    882\n",
      "1991    876\n",
      "2001    898\n",
      "2011    912\n",
      "Name: 33, dtype: object\n",
      "[893.28571429]\n",
      "[893.07142857]\n",
      "[892.85714286]\n",
      "[892.64285714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],33]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    940\n",
      "1961    947\n",
      "1971    940\n",
      "1981    936\n",
      "1991    936\n",
      "2001    962\n",
      "2011    963\n",
      "Name: 34, dtype: object\n",
      "[959.85714286]\n",
      "[963.25]\n",
      "[966.64285714]\n",
      "[970.03571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],34]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951    865\n",
      "1961    878\n",
      "1971    891\n",
      "1981    911\n",
      "1991    917\n",
      "2001    934\n",
      "2011    950\n",
      "Name: 35, dtype: object\n",
      "[962.71428571]\n",
      "[976.75]\n",
      "[990.78571429]\n",
      "[1004.82142857]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAHE\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:563: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rf=sexr.transpose()\n",
    "x= [\"1951\",\"1961\",\"1971\",\"1981\",\"1991\",\"2001\",\"2011\"]\n",
    "x=np.array([x])\n",
    "x=x.reshape(-1,1)\n",
    "y= rf.iloc[[1,2,3,4,5,6,7],35]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(x,y)\n",
    "for i in range (2021,2052,10):\n",
    "      y_pred = reg.predict([[i]])\n",
    "      print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                         State         2021         2031         2041  \\\n",
       "0                       India   932.285714   931.285714   930.285714   \n",
       "1   Andaman & Nicobar Islands   938.714286   988.178571  1037.642857   \n",
       "2              Andhra Pradesh   981.714286   982.071429   982.428571   \n",
       "3           Arunachal Pradesh   889.677551   888.824490   887.971429   \n",
       "4                       Assam   969.714286   985.035714  1000.357143   \n",
       "5                       Bihar   883.714286   867.000000   850.285714   \n",
       "6                  Chandigarh   819.714286   834.071428   848.428571   \n",
       "7                Chhattisgarh   977.285714   971.928571   966.571429   \n",
       "8        Dadra & Nagar Haveli   793.571429   762.392857   731.214286   \n",
       "9                 Daman & Diu   597.571429   505.821429   414.071429   \n",
       "10                      Delhi   868.000000   882.214286   896.428571   \n",
       "11                        Goa   908.857143   884.250000   859.642857   \n",
       "12                    Gujarat   914.571429   909.607143   904.642857   \n",
       "13                    Haryana   869.857143   870.142857   870.428571   \n",
       "14           Himachal Pradesh   993.571429  1002.785714  1012.000000   \n",
       "15            Jammu & Kashmir   898.857143   902.214286   905.571429   \n",
       "16                  Jharkhand   931.000000   927.428571   923.857143   \n",
       "17                  Karnataka   968.428571   969.714286   971.000000   \n",
       "18                     Kerala  1076.571429  1085.857143  1095.142857   \n",
       "19                Lakshadweep   911.857143   895.071429   878.285714   \n",
       "20             Madhya Pradesh   914.857143   912.142857   909.428571   \n",
       "21                Maharashtra   924.142857   922.000000   919.857143   \n",
       "22                    Manipur   955.714286   947.285714   938.857143   \n",
       "23                  Meghalaya   985.857143   993.107143  1000.357143   \n",
       "24                    Mizoram   911.285714   898.142857   885.000000   \n",
       "25                   Nagaland   875.428571   866.321429   857.214286   \n",
       "26                     Odisha   958.571429   951.285714   944.000000   \n",
       "27                 Puducherry  1003.000000  1002.535714  1002.071429   \n",
       "28                     Punjab   901.285714   908.928571   916.571429   \n",
       "29                  Rajasthan   923.428571   925.071429   926.714286   \n",
       "30                     Sikkim   865.428571   862.071429   858.714286   \n",
       "31                 Tamil Nadu   980.571429   978.892857   977.214286   \n",
       "32                    Tripura   968.571429   975.785714   983.000000   \n",
       "33              Uttar Pradesh   893.285714   893.071429   892.857143   \n",
       "34                Uttarakhand   959.857143   963.250000   966.642857   \n",
       "35                West Bengal   962.714286   976.750000   990.785714   \n",
       "\n",
       "           2051  \n",
       "0    929.285714  \n",
       "1   1087.107143  \n",
       "2    982.785714  \n",
       "3    887.118367  \n",
       "4   1015.678571  \n",
       "5    833.571429  \n",
       "6    862.785714  \n",
       "7    961.214286  \n",
       "8    700.035714  \n",
       "9    322.321429  \n",
       "10   910.642857  \n",
       "11   835.035714  \n",
       "12   899.678571  \n",
       "13   870.714286  \n",
       "14  1021.214286  \n",
       "15   908.928571  \n",
       "16   920.285714  \n",
       "17   972.285714  \n",
       "18  1104.428571  \n",
       "19   861.500000  \n",
       "20   906.714286  \n",
       "21   917.714286  \n",
       "22   930.428571  \n",
       "23  1007.607143  \n",
       "24   871.857143  \n",
       "25   848.107143  \n",
       "26   936.714286  \n",
       "27  1001.607143  \n",
       "28   924.214286  \n",
       "29   928.357143  \n",
       "30   855.357143  \n",
       "31   975.535714  \n",
       "32   990.214286  \n",
       "33   892.642857  \n",
       "34   970.035714  \n",
       "35  1004.821429  >"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prese.info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting the positions and width for the bars\n",
    "pos = list(range(len(prese['2021']))) \n",
    "width = 0.20\n",
    "    \n",
    "# Plotting the bars\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "\n",
    "# Create a bar with pre_score data,\n",
    "# in position pos,\n",
    "plt.bar(pos, \n",
    "        #using df['pre_score'] data,\n",
    "        prese['2021'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#EE3224', \n",
    "        # with label the first value in first_name\n",
    "        label=prese['State'][0]) \n",
    "\n",
    "# Create a bar with mid_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width for p in pos], \n",
    "        #using df['mid_score'] data,\n",
    "        prese['2031'],\n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#F78F1E', \n",
    "        # with label the second value in first_name\n",
    "        label=prese['State'][1]) \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width*2 for p in pos], \n",
    "        #using df['post_score'] data,\n",
    "        prese['2041'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#FFC222', \n",
    "        # with label the third value in first_name\n",
    "        label=prese['State'][2]) \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width*3 for p in pos], \n",
    "        #using df['post_score'] data,\n",
    "        prese['2051'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='blue', \n",
    "        # with label the third value in first_name\n",
    "        label=prese['State'][3]) \n",
    "\n",
    "# Set the y axis label\n",
    "ax.set_ylabel('no. of females per 1000 males')\n",
    "\n",
    "# Set the chart's title\n",
    "ax.set_title('Sex Ratio')\n",
    "\n",
    "# Set the position of the x ticks\n",
    "ax.set_xticks([p + 1.5 * width for p in pos])\n",
    "\n",
    "# Set the labels for the x ticks\n",
    "ax.set_xticklabels(prese['State'], rotation ='vertical')\n",
    "\n",
    "# Setting the x-axis and y-axis limits\n",
    "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "plt.ylim([0, 1200])\n",
    "\n",
    "# Adding the legend and showing the plot\n",
    "plt.legend(['2021', '2031', '2041','2051'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    494.7\n",
      "Unnamed: 2    464.2\n",
      "Unnamed: 3    415.8\n",
      "Unnamed: 4      381\n",
      "Name: 2, dtype: object\n",
      "[8225.85714286]\n",
      "[[-3.84285714]]\n",
      "[[421.01428571]]\n",
      "Unnamed: 5    611.7\n",
      "Unnamed: 6    751.6\n",
      "Unnamed: 7    848.2\n",
      "Unnamed: 8    889.7\n",
      "Name: 2, dtype: object\n",
      "[-17325.74364286]\n",
      "[[0.89292857]]\n",
      "[[810.52857143]]\n",
      "Unnamed: 9     104.2\n",
      "Unnamed: 10    131.1\n",
      "Unnamed: 11    179.3\n",
      "Unnamed: 12    239.4\n",
      "Name: 2, dtype: object\n",
      "[-9228.37085714]\n",
      "[[0.46364286]]\n",
      "[[189.14285714]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 2]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 2]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 2]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    17.2\n",
      "Unnamed: 2    14.9\n",
      "Unnamed: 3    13.3\n",
      "Unnamed: 4    11.6\n",
      "Name: 3, dtype: object\n",
      "[386.17642857]\n",
      "[[-0.18357143]]\n",
      "[[13.34285714]]\n",
      "Unnamed: 5    27.2\n",
      "Unnamed: 6    31.3\n",
      "Unnamed: 7    32.6\n",
      "Unnamed: 8    31.9\n",
      "Name: 3, dtype: object\n",
      "[-250.39528571]\n",
      "[[0.01385714]]\n",
      "[[31.05714286]]\n",
      "Unnamed: 9        5\n",
      "Unnamed: 10     6.3\n",
      "Unnamed: 11     8.3\n",
      "Unnamed: 12    10.9\n",
      "Name: 3, dtype: object\n",
      "[-400.39885714]\n",
      "[[0.02014286]]\n",
      "[[8.74285714]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 3]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 3]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 3]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    13.3\n",
      "Unnamed: 2    11.9\n",
      "Unnamed: 3    10.5\n",
      "Unnamed: 4    10.2\n",
      "Name: 4, dtype: object\n",
      "[215.67928571]\n",
      "[[-0.10071429]]\n",
      "[[11.12857143]]\n",
      "Unnamed: 5    15.8\n",
      "Unnamed: 6      19\n",
      "Unnamed: 7    21.7\n",
      "Unnamed: 8    22.2\n",
      "Name: 4, dtype: object\n",
      "[-397.45485714]\n",
      "[[0.02057143]]\n",
      "[[20.37142857]]\n",
      "Unnamed: 9     2.1\n",
      "Unnamed: 10    2.6\n",
      "Unnamed: 11    3.9\n",
      "Unnamed: 12    5.5\n",
      "Name: 4, dtype: object\n",
      "[-235.20571429]\n",
      "[[0.01178571]]\n",
      "[[4.18571429]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 4]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 4]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 4]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    51.4\n",
      "Unnamed: 2    53.5\n",
      "Unnamed: 3    48.9\n",
      "Unnamed: 4    46.2\n",
      "Name: 5, dtype: object\n",
      "[456.67928571]\n",
      "[[-0.20071429]]\n",
      "[[49.02857143]]\n",
      "Unnamed: 5      45\n",
      "Unnamed: 6    60.1\n",
      "Unnamed: 7    77.9\n",
      "Unnamed: 8    89.4\n",
      "Name: 5, dtype: object\n",
      "[-2926.98992857]\n",
      "[[0.14778571]]\n",
      "[[74.68571429]]\n",
      "Unnamed: 9      7.7\n",
      "Unnamed: 10     9.4\n",
      "Unnamed: 11    12.7\n",
      "Unnamed: 12    17.8\n",
      "Name: 5, dtype: object\n",
      "[-694.06114286]\n",
      "[[0.03485714]]\n",
      "[[13.95714286]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 5]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 5]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 5]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    10.8\n",
      "Unnamed: 2    10.3\n",
      "Unnamed: 3     9.4\n",
      "Unnamed: 4     8.8\n",
      "Name: 6, dtype: object\n",
      "[147.33214286]\n",
      "[[-0.06785714]]\n",
      "[[9.51428571]]\n",
      "Unnamed: 5    12.7\n",
      "Unnamed: 6    15.7\n",
      "Unnamed: 7    17.8\n",
      "Unnamed: 8      19\n",
      "Name: 6, dtype: object\n",
      "[-396.31678571]\n",
      "[[0.02035714]]\n",
      "[[17.15714286]]\n",
      "Unnamed: 9       2\n",
      "Unnamed: 10    2.6\n",
      "Unnamed: 11    3.5\n",
      "Unnamed: 12    4.7\n",
      "Name: 6, dtype: object\n",
      "[-183.44628571]\n",
      "[[0.00921429]]\n",
      "[[3.71428571]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 6]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 6]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 6]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    6.2\n",
      "Unnamed: 2    5.4\n",
      "Unnamed: 3    4.6\n",
      "Unnamed: 4    4.1\n",
      "Name: 7, dtype: object\n",
      "[145.49071429]\n",
      "[[-0.06928571]]\n",
      "[[4.77142857]]\n",
      "Unnamed: 5     9.4\n",
      "Unnamed: 6    11.3\n",
      "Unnamed: 7    12.1\n",
      "Unnamed: 8    11.8\n",
      "Name: 7, dtype: object\n",
      "[-135.21507143]\n",
      "[[0.00721429]]\n",
      "[[11.31428571]]\n",
      "Unnamed: 9     1.1\n",
      "Unnamed: 10    1.8\n",
      "Unnamed: 11    2.9\n",
      "Unnamed: 12    4.3\n",
      "Name: 7, dtype: object\n",
      "[-218.85257143]\n",
      "[[0.01092857]]\n",
      "[[3.12857143]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 7]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 7]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 7]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    23.4\n",
      "Unnamed: 2    22.3\n",
      "Unnamed: 3    20.6\n",
      "Unnamed: 4    18.9\n",
      "Name: 8, dtype: object\n",
      "[330.96714286]\n",
      "[[-0.15285714]]\n",
      "[[20.51428571]]\n",
      "Unnamed: 5    32.2\n",
      "Unnamed: 6    38.2\n",
      "Unnamed: 7    41.9\n",
      "Unnamed: 8    43.5\n",
      "Name: 8, dtype: object\n",
      "[-692.27535714]\n",
      "[[0.03607143]]\n",
      "[[40.37142857]]\n",
      "Unnamed: 9      4.8\n",
      "Unnamed: 10     6.7\n",
      "Unnamed: 11     9.5\n",
      "Unnamed: 12    12.8\n",
      "Name: 8, dtype: object\n",
      "[-542.86228571]\n",
      "[[0.02721429]]\n",
      "[[9.91428571]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 8]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 8]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 8]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    10.2\n",
      "Unnamed: 2     9.4\n",
      "Unnamed: 3     8.5\n",
      "Unnamed: 4     7.8\n",
      "Name: 9, dtype: object\n",
      "[171.08]\n",
      "[[-0.08]]\n",
      "[[8.6]]\n",
      "Unnamed: 5    12.9\n",
      "Unnamed: 6      16\n",
      "Unnamed: 7    17.9\n",
      "Unnamed: 8    18.6\n",
      "Name: 9, dtype: object\n",
      "[-351.45671429]\n",
      "[[0.01814286]]\n",
      "[[17.04285714]]\n",
      "Unnamed: 9     2.2\n",
      "Unnamed: 10    2.7\n",
      "Unnamed: 11    3.6\n",
      "Unnamed: 12      5\n",
      "Name: 9, dtype: object\n",
      "[-191.92285714]\n",
      "[[0.00964286]]\n",
      "[[3.94285714]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 9]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 9]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 9]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    2.4\n",
      "Unnamed: 2    2.1\n",
      "Unnamed: 3    1.9\n",
      "Unnamed: 4    1.7\n",
      "Name: 10, dtype: object\n",
      "[48.33714286]\n",
      "[[-0.02285714]]\n",
      "[[1.91428571]]\n",
      "Unnamed: 5    3.7\n",
      "Unnamed: 6    4.3\n",
      "Unnamed: 7    4.6\n",
      "Unnamed: 8    4.5\n",
      "Name: 10, dtype: object\n",
      "[-44.99814286]\n",
      "[[0.00242857]]\n",
      "[[4.32857143]]\n",
      "Unnamed: 9     0.7\n",
      "Unnamed: 10    0.9\n",
      "Unnamed: 11    1.2\n",
      "Unnamed: 12    1.7\n",
      "Name: 10, dtype: object\n",
      "[-68.31257143]\n",
      "[[0.00342857]]\n",
      "[[1.32857143]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 10]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 10]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 10]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    5.5\n",
      "Unnamed: 2    4.6\n",
      "Unnamed: 3    3.6\n",
      "Unnamed: 4    3.6\n",
      "Name: 11, dtype: object\n",
      "[128.91857143]\n",
      "[[-0.06142857]]\n",
      "[[4.15714286]]\n",
      "Unnamed: 5    6.1\n",
      "Unnamed: 6    7.8\n",
      "Unnamed: 7    9.3\n",
      "Unnamed: 8    9.3\n",
      "Name: 11, dtype: object\n",
      "[-199.04807143]\n",
      "[[0.01021429]]\n",
      "[[8.41428571]]\n",
      "Unnamed: 9     0.9\n",
      "Unnamed: 10    1.2\n",
      "Unnamed: 11    1.9\n",
      "Unnamed: 12    2.7\n",
      "Name: 11, dtype: object\n",
      "[-124.21028571]\n",
      "[[0.00621429]]\n",
      "[[2.01428571]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 11]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 11]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 11]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    15.2\n",
      "Unnamed: 2    14.6\n",
      "Unnamed: 3    12.8\n",
      "Unnamed: 4    12.5\n",
      "Name: 12, dtype: object\n",
      "[200.62785714]\n",
      "[[-0.09214286]]\n",
      "[[13.48571429]]\n",
      "Unnamed: 5    15.5\n",
      "Unnamed: 6    19.8\n",
      "Unnamed: 7    24.1\n",
      "Unnamed: 8    26.2\n",
      "Name: 12, dtype: object\n",
      "[-690.94371429]\n",
      "[[0.03514286]]\n",
      "[[22.84285714]]\n",
      "Unnamed: 9     2.4\n",
      "Unnamed: 10    3.2\n",
      "Unnamed: 11    4.4\n",
      "Unnamed: 12      6\n",
      "Name: 12, dtype: object\n",
      "[-244.86171429]\n",
      "[[0.01228571]]\n",
      "[[4.68571429]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 12]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 12]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 12]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    21.9\n",
      "Unnamed: 2    19.6\n",
      "Unnamed: 3      17\n",
      "Unnamed: 4    14.9\n",
      "Name: 13, dtype: object\n",
      "[491.62642857]\n",
      "[[-0.23357143]]\n",
      "[[17.24285714]]\n",
      "Unnamed: 5    33.4\n",
      "Unnamed: 6    38.8\n",
      "Unnamed: 7    41.2\n",
      "Unnamed: 8    40.8\n",
      "Name: 13, dtype: object\n",
      "[-419.27685714]\n",
      "[[0.02257143]]\n",
      "[[39.17142857]]\n",
      "Unnamed: 9     5.8\n",
      "Unnamed: 10    7.3\n",
      "Unnamed: 11    9.9\n",
      "Unnamed: 12     13\n",
      "Name: 13, dtype: object\n",
      "[-490.20285714]\n",
      "[[0.02464286]]\n",
      "[[10.34285714]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 13]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 13]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 13]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    10.5\n",
      "Unnamed: 2     9.8\n",
      "Unnamed: 3     9.3\n",
      "Unnamed: 4     8.8\n",
      "Name: 14, dtype: object\n",
      "[122.48428571]\n",
      "[[-0.05571429]]\n",
      "[[9.32857143]]\n",
      "Unnamed: 5    18.8\n",
      "Unnamed: 6      20\n",
      "Unnamed: 7    20.3\n",
      "Unnamed: 8      20\n",
      "Name: 14, dtype: object\n",
      "[-49.80914286]\n",
      "[[0.00342857]]\n",
      "[[19.82857143]]\n",
      "Unnamed: 9     4.2\n",
      "Unnamed: 10    5.8\n",
      "Unnamed: 11    7.6\n",
      "Unnamed: 12      9\n",
      "Name: 14, dtype: object\n",
      "[-317.592]\n",
      "[[0.016]]\n",
      "[[7.4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 14]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 14]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 14]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    31.8\n",
      "Unnamed: 2    31.3\n",
      "Unnamed: 3    28.4\n",
      "Unnamed: 4    25.9\n",
      "Name: 15, dtype: object\n",
      "[448.99285714]\n",
      "[[-0.20714286]]\n",
      "[[28.28571429]]\n",
      "Unnamed: 5    35.1\n",
      "Unnamed: 6    44.3\n",
      "Unnamed: 7    51.4\n",
      "Unnamed: 8    56.2\n",
      "Name: 15, dtype: object\n",
      "[-1347.32092857]\n",
      "[[0.06878571]]\n",
      "[[49.78571429]]\n",
      "Unnamed: 9      5.7\n",
      "Unnamed: 10     6.9\n",
      "Unnamed: 11     9.4\n",
      "Unnamed: 12    12.7\n",
      "Name: 15, dtype: object\n",
      "[-480.34685714]\n",
      "[[0.02414286]]\n",
      "[[10.04285714]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 15]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 15]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 15]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    40.7\n",
      "Unnamed: 2    35.6\n",
      "Unnamed: 3    30.4\n",
      "Unnamed: 4    27.1\n",
      "Name: 16, dtype: object\n",
      "[943.97071429]\n",
      "[[-0.44928571]]\n",
      "[[31.47142857]]\n",
      "Unnamed: 5    60.5\n",
      "Unnamed: 6    71.2\n",
      "Unnamed: 7    76.6\n",
      "Unnamed: 8    75.4\n",
      "Name: 16, dtype: object\n",
      "[-853.52985714]\n",
      "[[0.04557143]]\n",
      "[[72.07142857]]\n",
      "Unnamed: 9     11.1\n",
      "Unnamed: 10    13.9\n",
      "Unnamed: 11    18.8\n",
      "Unnamed: 12    25.2\n",
      "Name: 16, dtype: object\n",
      "[-962.27314286]\n",
      "[[0.04835714]]\n",
      "[[19.95714286]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 16]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 16]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 16]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1      16\n",
      "Unnamed: 2    14.8\n",
      "Unnamed: 3    13.7\n",
      "Unnamed: 4    13.1\n",
      "Name: 17, dtype: object\n",
      "[206.945]\n",
      "[[-0.095]]\n",
      "[[14.]]\n",
      "Unnamed: 5    21.9\n",
      "Unnamed: 6    25.7\n",
      "Unnamed: 7    28.1\n",
      "Unnamed: 8    28.7\n",
      "Name: 17, dtype: object\n",
      "[-411.26585714]\n",
      "[[0.02157143]]\n",
      "[[26.87142857]]\n",
      "Unnamed: 9       4\n",
      "Unnamed: 10    4.9\n",
      "Unnamed: 11    6.5\n",
      "Unnamed: 12    8.3\n",
      "Name: 17, dtype: object\n",
      "[-292.16228571]\n",
      "[[0.01471429]]\n",
      "[[6.71428571]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 17]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 17]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 17]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    31.2\n",
      "Unnamed: 2    30.1\n",
      "Unnamed: 3    27.2\n",
      "Unnamed: 4    25.3\n",
      "Name: 19, dtype: object\n",
      "[439.51714286]\n",
      "[[-0.20285714]]\n",
      "[[27.51428571]]\n",
      "Unnamed: 5    32.3\n",
      "Unnamed: 6      42\n",
      "Unnamed: 7      50\n",
      "Unnamed: 8    55.1\n",
      "Name: 19, dtype: object\n",
      "[-1465.0695]\n",
      "[[0.0745]]\n",
      "[[48.1]]\n",
      "Unnamed: 9      5.1\n",
      "Unnamed: 10     6.5\n",
      "Unnamed: 11       9\n",
      "Unnamed: 12    12.3\n",
      "Name: 19, dtype: object\n",
      "[-492.38228571]\n",
      "[[0.02471429]]\n",
      "[[9.61428571]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 19]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 19]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 19]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    23.3\n",
      "Unnamed: 2    20.6\n",
      "Unnamed: 3    18.1\n",
      "Unnamed: 4      16\n",
      "Name: 20, dtype: object\n",
      "[508.69857143]\n",
      "[[-0.24142857]]\n",
      "[[18.35714286]]\n",
      "Unnamed: 5    41.3\n",
      "Unnamed: 6    45.5\n",
      "Unnamed: 7    46.3\n",
      "Unnamed: 8    44.2\n",
      "Name: 20, dtype: object\n",
      "[-105.27378571]\n",
      "[[0.00735714]]\n",
      "[[44.15714286]]\n",
      "Unnamed: 9      7.5\n",
      "Unnamed: 10    10.1\n",
      "Unnamed: 11    13.7\n",
      "Unnamed: 12    17.5\n",
      "Name: 20, dtype: object\n",
      "[-673.74914286]\n",
      "[[0.03385714]]\n",
      "[[13.95714286]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 20]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 20]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 20]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1      13\n",
      "Unnamed: 2    11.4\n",
      "Unnamed: 3    10.4\n",
      "Unnamed: 4     9.4\n",
      "Name: 21, dtype: object\n",
      "[248.40285714]\n",
      "[[-0.11714286]]\n",
      "[[10.48571429]]\n",
      "Unnamed: 5    18.9\n",
      "Unnamed: 6    22.6\n",
      "Unnamed: 7    24.2\n",
      "Unnamed: 8      24\n",
      "Name: 21, dtype: object\n",
      "[-293.39985714]\n",
      "[[0.01557143]]\n",
      "[[22.87142857]]\n",
      "Unnamed: 9     3.2\n",
      "Unnamed: 10      4\n",
      "Unnamed: 11    5.4\n",
      "Unnamed: 12    7.4\n",
      "Name: 21, dtype: object\n",
      "[-287.24457143]\n",
      "[[0.01442857]]\n",
      "[[5.82857143]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 21]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 21]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 21]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 1    4.3\n",
      "Unnamed: 2      4\n",
      "Unnamed: 3    3.6\n",
      "Unnamed: 4    3.1\n",
      "Name: 23, dtype: object\n",
      "[86.21928571]\n",
      "[[-0.04071429]]\n",
      "[[3.52857143]]\n",
      "Unnamed: 5    4.9\n",
      "Unnamed: 6    6.3\n",
      "Unnamed: 7    7.1\n",
      "Unnamed: 8    7.7\n",
      "Name: 23, dtype: object\n",
      "[-175.899]\n",
      "[[0.009]]\n",
      "[[6.9]]\n",
      "Unnamed: 9     0.9\n",
      "Unnamed: 10    1.1\n",
      "Unnamed: 11    1.5\n",
      "Unnamed: 12      2\n",
      "Name: 23, dtype: object\n",
      "[-75.30971429]\n",
      "[[0.00378571]]\n",
      "[[1.58571429]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 0]\n",
    "y= rd.iloc[[1,2,3,4], 23]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[5,6,7,8], 0]\n",
    "y= rd.iloc[[5,6,7,8], 23]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=age.transpose()\n",
    "x= rd.iloc[[9,10,11,12], 0]\n",
    "y= rd.iloc[[9,10,11,12], 23]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of               States   2011   2021   2031   2041  20111  20211  20311  20411  \\\n",
       "0                NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1              INDIA  494.7  464.2  415.8  381.0  611.7  751.6  848.2  889.7   \n",
       "2     Andhra Pradesh   17.2   14.9   13.3   11.6   27.2   31.3   32.6   31.9   \n",
       "3              Assam   13.3   11.9   10.5   10.2   15.8   19.0   21.7   22.2   \n",
       "4              Bihar   51.4   53.5   48.9   46.2   45.0   60.1   77.9   89.4   \n",
       "5       Chhattisgarh   10.8   10.3    9.4    8.8   12.7   15.7   17.8   19.0   \n",
       "6              Delhi    6.2    5.4    4.6    4.1    9.4   11.3   12.1   11.8   \n",
       "7            Gujarat   23.4   22.3   20.6   18.9   32.2   38.2   41.9   43.5   \n",
       "8            Haryana   10.2    9.4    8.5    7.8   12.9   16.0   17.9   18.6   \n",
       "9   Himachal Pradesh    2.4    2.1    1.9    1.7    3.7    4.3    4.6    4.5   \n",
       "10             Jammu    5.5    4.6    3.6    3.6    6.1    7.8    9.3    9.3   \n",
       "11          Jharkand   15.2   14.6   12.8   12.5   15.5   19.8   24.1   26.2   \n",
       "12         Karnataka   21.9   19.6   17.0   14.9   33.4   38.8   41.2   40.8   \n",
       "13            Kerala   10.5    9.8    9.3    8.8   18.8   20.0   20.3   20.0   \n",
       "14    Madhya Pradesh   31.8   31.3   28.4   25.9   35.1   44.3   51.4   56.2   \n",
       "15       Maharashtra   40.7   35.6   30.4   27.1   60.5   71.2   76.6   75.4   \n",
       "16            Odisha   16.0   14.8   13.7   13.1   21.9   25.7   28.1   28.7   \n",
       "17            Punjab    9.9    8.4    7.4    6.6   15.0   17.7   18.6   18.3   \n",
       "18          Rajastan   31.2   30.1   27.2   25.3   32.3   42.0   50.0   55.1   \n",
       "19        Tamil Nadu   23.3   20.6   18.1   16.0   41.3   45.5   46.3   44.2   \n",
       "20         Telangana   13.0   11.4   10.4    9.4   18.9   22.6   24.2   24.0   \n",
       "21     Uttar Pradesh   95.1   90.3   81.8   74.5   89.1  120.9  145.0  162.2   \n",
       "22       Uttarakhand    4.3    4.0    3.6    3.1    4.9    6.3    7.1    7.7   \n",
       "23       West Bengal   33.8   28.5   24.9   22.8   49.7   58.5   62.2   60.9   \n",
       "\n",
       "    20112  20212  20312  20412  \n",
       "0     NaN    NaN    NaN    NaN  \n",
       "1   104.2  131.1  179.3  239.4  \n",
       "2     5.0    6.3    8.3   10.9  \n",
       "3     2.1    2.6    3.9    5.5  \n",
       "4     7.7    9.4   12.7   17.8  \n",
       "5     2.0    2.6    3.5    4.7  \n",
       "6     1.1    1.8    2.9    4.3  \n",
       "7     4.8    6.7    9.5   12.8  \n",
       "8     2.2    2.7    3.6    5.0  \n",
       "9     0.7    0.9    1.2    1.7  \n",
       "10    0.9    1.2    1.9    2.7  \n",
       "11    2.4    3.2    4.4    6.0  \n",
       "12    5.8    7.3    9.9   13.0  \n",
       "13    4.2    5.8    7.6    9.0  \n",
       "14    5.7    6.9    9.4   12.7  \n",
       "15   11.1   13.9   18.8   25.2  \n",
       "16    4.0    4.9    6.5    8.3  \n",
       "17    2.9    3.7    4.9    6.4  \n",
       "18    5.1    6.5    9.0   12.3  \n",
       "19    7.5   10.1   13.7   17.5  \n",
       "20    3.2    4.0    5.4    7.4  \n",
       "21   15.6   18.1   23.8   32.3  \n",
       "22    0.9    1.1    1.5    2.0  \n",
       "23    7.8   10.8   15.6   20.5  >"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age1.info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting the positions and width for the bars\n",
    "pos = list(range(len(age1['2011']))) \n",
    "width = 0.20\n",
    "    \n",
    "# Plotting the bars\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "\n",
    "# Create a bar with pre_score data,\n",
    "# in position pos,\n",
    "plt.bar(pos, \n",
    "        #using df['pre_score'] data,\n",
    "        age1['2011'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#EE3224', \n",
    "        # with label the first value in first_name\n",
    "        label=age1['States'][0]) \n",
    "\n",
    "# Create a bar with mid_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width for p in pos], \n",
    "        #using df['mid_score'] data,\n",
    "        age1['2021'],\n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#F78F1E', \n",
    "        # with label the second value in first_name\n",
    "        label=age1['States'][1]) \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width*2 for p in pos], \n",
    "        #using df['post_score'] data,\n",
    "        age1['2031'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#FFC222', \n",
    "        # with label the third value in first_name\n",
    "        label=age1['States'][2]) \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width*3 for p in pos], \n",
    "        #using df['post_score'] data,\n",
    "        age1['2041'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='blue', \n",
    "        # with label the third value in first_name\n",
    "        label=age1['States'][3]) \n",
    "\n",
    "# Set the y axis label\n",
    "ax.set_ylabel('No. in Million')\n",
    "\n",
    "# Set the chart's title\n",
    "ax.set_title('0-19 Age Distribution')\n",
    "\n",
    "# Set the position of the x ticks\n",
    "ax.set_xticks([p + 1.5 * width for p in pos])\n",
    "\n",
    "# Set the labels for the x ticks\n",
    "ax.set_xticklabels(age1['States'])\n",
    "\n",
    "# Setting the x-axis and y-axis limits\n",
    "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "#plt.ylim([0, max(age1['2011'] + age1['2021'] + age1['2031'] + age1['2041'])] )\n",
    "\n",
    "# Adding the legend and showing the plot\n",
    "plt.legend(['2011', '2021', '2031','2041'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting the positions and width for the bars\n",
    "pos = list(range(len(age1['20111']))) \n",
    "width = 0.20\n",
    "    \n",
    "# Plotting the bars\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "\n",
    "# Create a bar with pre_score data,\n",
    "# in position pos,\n",
    "plt.bar(pos, \n",
    "        #using df['pre_score'] data,\n",
    "        age1['20111'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#EE3224', \n",
    "        # with label the first value in first_name\n",
    "        label=age1['States'][0]) \n",
    "\n",
    "# Create a bar with mid_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width for p in pos], \n",
    "        #using df['mid_score'] data,\n",
    "        age1['20211'],\n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#F78F1E', \n",
    "        # with label the second value in first_name\n",
    "        label=age1['States'][1]) \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width*2 for p in pos], \n",
    "        #using df['post_score'] data,\n",
    "        age1['20311'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#FFC222', \n",
    "        # with label the third value in first_name\n",
    "        label=age1['States'][2]) \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width*3 for p in pos], \n",
    "        #using df['post_score'] data,\n",
    "        age1['20411'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='blue', \n",
    "        # with label the third value in first_name\n",
    "        label=age1['States'][3]) \n",
    "\n",
    "# Set the y axis label\n",
    "ax.set_ylabel('No. in Million')\n",
    "\n",
    "# Set the chart's title\n",
    "ax.set_title('20-59 Age Distribution')\n",
    "\n",
    "# Set the position of the x ticks\n",
    "ax.set_xticks([p + 1.5 * width for p in pos])\n",
    "\n",
    "# Set the labels for the x ticks\n",
    "ax.set_xticklabels(age1['States'])\n",
    "\n",
    "# Setting the x-axis and y-axis limits\n",
    "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "#plt.ylim([0, max(age1['2011'] + age1['2021'] + age1['2031'] + age1['2041'])] )\n",
    "\n",
    "# Adding the legend and showing the plot\n",
    "plt.legend(['2011', '2021', '2031','2041'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting the positions and width for the bars\n",
    "pos = list(range(len(age1['20112']))) \n",
    "width = 0.20\n",
    "    \n",
    "# Plotting the bars\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "\n",
    "# Create a bar with pre_score data,\n",
    "# in position pos,\n",
    "plt.bar(pos, \n",
    "        #using df['pre_score'] data,\n",
    "        age1['20112'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#EE3224', \n",
    "        # with label the first value in first_name\n",
    "        label=age1['States'][0]) \n",
    "\n",
    "# Create a bar with mid_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width for p in pos], \n",
    "        #using df['mid_score'] data,\n",
    "        age1['20212'],\n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#F78F1E', \n",
    "        # with label the second value in first_name\n",
    "        label=age1['States'][1]) \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width*2 for p in pos], \n",
    "        #using df['post_score'] data,\n",
    "        age1['20312'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#FFC222', \n",
    "        # with label the third value in first_name\n",
    "        label=age1['States'][2]) \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width*3 for p in pos], \n",
    "        #using df['post_score'] data,\n",
    "        age1['20412'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='blue', \n",
    "        # with label the third value in first_name\n",
    "        label=age1['States'][3]) \n",
    "\n",
    "# Set the y axis label\n",
    "ax.set_ylabel('No. in Million')\n",
    "\n",
    "# Set the chart's title\n",
    "ax.set_title('60+ Age Distribution')\n",
    "\n",
    "# Set the position of the x ticks\n",
    "ax.set_xticks([p + 1.5 * width for p in pos])\n",
    "\n",
    "# Set the labels for the x ticks\n",
    "ax.set_xticklabels(age1['States'])\n",
    "\n",
    "# Setting the x-axis and y-axis limits\n",
    "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "#plt.ylim([0, max(age1['2011'] + age1['2021'] + age1['2031'] + age1['2041'])] )\n",
    "\n",
    "# Adding the legend and showing the plot\n",
    "plt.legend(['2011', '2021', '2031','2041'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of               States  2011   2021  2031  2041\n",
       "0                NaN   NaN    NaN   NaN   NaN\n",
       "1     Andhra Pradesh  65.8  66.30  67.0  67.9\n",
       "2              Assam  61.9  62.20  62.7  63.3\n",
       "3              Bihar  65.8  66.30  67.2  67.7\n",
       "4       Chhattisgarh  62.4  62.90  63.3  63.7\n",
       "5              Delhi  71.1  72.40  72.8  73.0\n",
       "6            Gujarat  66.8  67.30  67.7  68.2\n",
       "7            Haryana  67.0  67.30  67.6  68.2\n",
       "8   Himachal Pradesh  70.0  70.10  70.5  71.0\n",
       "9    Jammu & Kashmir  70.1  70.50  71.0  72.0\n",
       "10         Jharkhand  63.4  64.10  65.8  66.1\n",
       "11         Karnataka  67.2  67.50  68.0  68.5\n",
       "12            Kerala  74.2  74.40  74.7  74.8\n",
       "13    Madhya Pradesh  62.4  62.80  63.3  63.8\n",
       "14       Maharashtra  69.9  70.30  70.8  71.3\n",
       "15            Odisha  63.0  63.70  64.3  64.8\n",
       "16            Punjab  69.3  69.80  70.3  71.1\n",
       "17         Rajasthan  66.5  66.80  67.2  67.5\n",
       "18        Tamil Nadu  68.9  69.40  69.8  70.2\n",
       "19     Uttar Pradesh  62.7  63.00  63.5  63.8\n",
       "20       Uttarakhand  69.2  70.20  70.8  71.4\n",
       "21       West Bengal  69.0  69.40  69.7  69.9\n",
       "22             India  66.9  67.13  67.0  67.5>"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "life.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011    61.9\n",
      "2021    62.2\n",
      "2031    62.7\n",
      "2041    63.3\n",
      "Name: 2, dtype: object\n",
      "[17.68365651]\n",
      "[[0.67174515]]\n",
      "[[62.69058172]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 2]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011    65.8\n",
      "2021    66.3\n",
      "2031    67.2\n",
      "2041    67.7\n",
      "Name: 3, dtype: object\n",
      "[6.76620499]\n",
      "[[0.89750693]]\n",
      "[[66.89916898]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 3]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011    62.4\n",
      "2021    62.9\n",
      "2031    63.3\n",
      "2041    63.7\n",
      "Name: 4, dtype: object\n",
      "[23.66481994]\n",
      "[[0.5900277]]\n",
      "[[63.1966759]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 4]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011    71.1\n",
      "2021    72.4\n",
      "2031    72.8\n",
      "2041      73\n",
      "Name: 5, dtype: object\n",
      "[20.45844875]\n",
      "[[0.77562327]]\n",
      "[[72.42520776]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 5]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011    66.8\n",
      "2021    67.3\n",
      "2031    67.7\n",
      "2041    68.2\n",
      "Name: 6, dtype: object\n",
      "[24.68171745]\n",
      "[[0.64127424]]\n",
      "[[67.64709141]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 6]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011      67\n",
      "2021    67.3\n",
      "2031    67.6\n",
      "2041    68.2\n",
      "Name: 7, dtype: object\n",
      "[29.5498615]\n",
      "[[0.56925208]]\n",
      "[[67.68975069]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 7]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011      70\n",
      "2021    70.1\n",
      "2031    70.5\n",
      "2041      71\n",
      "Name: 8, dtype: object\n",
      "[37.21800554]\n",
      "[[0.49722992]]\n",
      "[[70.53240997]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 8]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011    70.1\n",
      "2021    70.5\n",
      "2031      71\n",
      "2041      72\n",
      "Name: 9, dtype: object\n",
      "[10.01717452]\n",
      "[[0.91274238]]\n",
      "[[71.17091413]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 9]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011    63.4\n",
      "2021    64.1\n",
      "2031    65.8\n",
      "2041    66.1\n",
      "Name: 10, dtype: object\n",
      "[-20.60055402]\n",
      "[[1.27700831]]\n",
      "[[64.95900277]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 10]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011    67.2\n",
      "2021    67.5\n",
      "2031      68\n",
      "2041    68.5\n",
      "Name: 11, dtype: object\n",
      "[26.366759]\n",
      "[[0.62049861]]\n",
      "[[67.9401662]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 11]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011    74.2\n",
      "2021    74.4\n",
      "2031    74.7\n",
      "2041    74.8\n",
      "Name: 12, dtype: object\n",
      "[55.99944598]\n",
      "[[0.27700831]]\n",
      "[[74.55900277]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 12]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011    62.4\n",
      "2021    62.8\n",
      "2031    63.3\n",
      "2041    63.8\n",
      "Name: 13, dtype: object\n",
      "[19.23268698]\n",
      "[[0.6565097]]\n",
      "[[63.21883657]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 13]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011    69.9\n",
      "2021    70.3\n",
      "2031    70.8\n",
      "2041    71.3\n",
      "Name: 14, dtype: object\n",
      "[26.73268698]\n",
      "[[0.6565097]]\n",
      "[[70.71883657]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 14]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011      63\n",
      "2021    63.7\n",
      "2031    64.3\n",
      "2041    64.8\n",
      "Name: 15, dtype: object\n",
      "[9.44736842]\n",
      "[[0.81578947]]\n",
      "[[64.10526316]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 15]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011    69.3\n",
      "2021    69.8\n",
      "2031    70.3\n",
      "2041    71.1\n",
      "Name: 16, dtype: object\n",
      "[13.64930748]\n",
      "[[0.84626039]]\n",
      "[[70.34875346]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 16]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011    66.5\n",
      "2021    66.8\n",
      "2031    67.2\n",
      "2041    67.5\n",
      "Name: 17, dtype: object\n",
      "[35.81606648]\n",
      "[[0.466759]]\n",
      "[[67.08891967]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 17]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011    68.9\n",
      "2021    69.4\n",
      "2031    69.8\n",
      "2041    70.2\n",
      "Name: 18, dtype: object\n",
      "[30.16481994]\n",
      "[[0.5900277]]\n",
      "[[69.6966759]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 18]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011    62.7\n",
      "2021      63\n",
      "2031    63.5\n",
      "2041    63.8\n",
      "Name: 19, dtype: object\n",
      "[28.63296399]\n",
      "[[0.51800554]]\n",
      "[[63.33933518]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 19]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011    69.2\n",
      "2021    70.2\n",
      "2031    70.8\n",
      "2041    71.4\n",
      "Name: 20, dtype: object\n",
      "[5.26204986]\n",
      "[[0.97506925]]\n",
      "[[70.59168975]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 20]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011      69\n",
      "2021    69.4\n",
      "2031    69.7\n",
      "2041    69.9\n",
      "Name: 21, dtype: object\n",
      "[42.74819945]\n",
      "[[0.40027701]]\n",
      "[[69.566759]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 21]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011     66.9\n",
      "2021    67.13\n",
      "2031       67\n",
      "2041     67.5\n",
      "Name: 22, dtype: object\n",
      "[49.01415512]\n",
      "[[0.27243767]]\n",
      "[[67.26747922]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating the regressor\n",
    "rd=life.transpose()\n",
    "x= rd.iloc[[1,2,3,4], 1]\n",
    "y= rd.iloc[[1,2,3,4], 22]\n",
    "\n",
    "print (y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25, random_state = 0)\n",
    "xtrain= xtrain.values.reshape(-1, 1)\n",
    "ytrain= ytrain.values.reshape(-1, 1)\n",
    "xtest= xtest.values.reshape(-1,1)\n",
    "reg= LinearRegression()\n",
    "cv_scores = cross_val_score\n",
    "# Fitting the regressor to the training data\n",
    "reg.fit(xtrain,ytrain)\n",
    "# To retrieve the intercept\n",
    "print(reg.intercept_)\n",
    "# For retrieving the slope\n",
    "print( reg.coef_)\n",
    "y_pred = reg.predict(xtest)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting the positions and width for the bars\n",
    "pos = list(range(len(life['2011']))) \n",
    "width = 0.20\n",
    "    \n",
    "# Plotting the bars\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "\n",
    "# Create a bar with pre_score data,\n",
    "# in position pos,\n",
    "plt.bar(pos, \n",
    "        #using df['pre_score'] data,\n",
    "        life['2011'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#EE3224', \n",
    "        # with label the first value in first_name\n",
    "        label=life['States'][0]) \n",
    "\n",
    "# Create a bar with mid_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width for p in pos], \n",
    "        #using df['mid_score'] data,\n",
    "        life['2021'],\n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#F78F1E', \n",
    "        # with label the second value in first_name\n",
    "        label=life['States'][1]) \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width*2 for p in pos], \n",
    "        #using df['post_score'] data,\n",
    "        life['2031'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#FFC222', \n",
    "        # with label the third value in first_name\n",
    "        label=life['States'][2]) \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width*3 for p in pos], \n",
    "        #using df['post_score'] data,\n",
    "        life['2041'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='blue', \n",
    "        # with label the third value in first_name\n",
    "        label=life['States'][3]) \n",
    "\n",
    "# Set the y axis label\n",
    "ax.set_ylabel('Number of Years')\n",
    "\n",
    "# Set the chart's title\n",
    "ax.set_title('Life expectancy')\n",
    "\n",
    "# Set the position of the x ticks\n",
    "ax.set_xticks([p + 1.5 * width for p in pos])\n",
    "\n",
    "# Set the labels for the x ticks\n",
    "ax.set_xticklabels(life['States'])\n",
    "\n",
    "# Setting the x-axis and y-axis limits\n",
    "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "#plt.ylim([0, max(life['2011'] + life['2021'] + life['2031'] + life['2041'])] )\n",
    "\n",
    "# Adding the legend and showing the plot\n",
    "plt.legend(['2011', '2021', '2031','2041'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of               States  2011  2021  2031  2041\n",
       "0                NaN   NaN   NaN   NaN   NaN\n",
       "1              INDIA  1.77  1.12  0.72  0.46\n",
       "2     Andhra Pradesh  1.10  0.65  0.31  0.02\n",
       "3              Assam  1.71  0.74  0.77  0.48\n",
       "4              Bihar  2.54  1.82  1.34  1.00\n",
       "5       Chhattisgarh  2.26  1.17  0.76  0.57\n",
       "6              Delhi  2.12  1.00  0.62  0.30\n",
       "7            Gujarat  1.93  1.12  0.71  0.44\n",
       "8            Haryana  1.99  1.08  0.70  0.44\n",
       "9   Himachal Pradesh  1.29  0.64  0.57  0.24\n",
       "10   Jammu & Kashmir  2.36  0.88  0.82  0.49\n",
       "11         Jharkhand  2.24  1.39  0.97  0.82\n",
       "12         Karnataka  1.56  0.75  0.36  0.10\n",
       "13            Kerala  0.49  0.66  0.45  0.18\n",
       "14    Madhya Pradesh  2.03  1.36  0.81  0.64\n",
       "15       Maharashtra  1.60  0.73  0.42  0.15\n",
       "16            Odisha  1.40  0.82  0.63  0.38\n",
       "17            Punjab  1.39  0.71  0.42  0.11\n",
       "18         Rajasthan  2.13  1.47  0.96  0.75\n",
       "19        Tamil Nadu  1.56  0.56  0.25 -0.05\n",
       "20         Telangana   NaN  0.80  0.53  0.21\n",
       "21     Uttar Pradesh  2.02  1.48  0.93  0.73\n",
       "22       Uttarakhand  1.88  1.30  0.70  0.50\n",
       "23       West Bengal  1.38  0.71  0.50  0.14>"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popgro.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of           Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3  Unnamed: 4  \\\n",
       "0             States      2011.0      2021.0      2031.0      2041.0   \n",
       "1                NaN         NaN         NaN         NaN         NaN   \n",
       "2              INDIA       494.7       464.2       415.8       381.0   \n",
       "3     Andhra Pradesh        17.2        14.9        13.3        11.6   \n",
       "4             Assam         13.3        11.9        10.5        10.2   \n",
       "5              Bihar        51.4        53.5        48.9        46.2   \n",
       "6       Chhattisgarh        10.8        10.3         9.4         8.8   \n",
       "7              Delhi         6.2         5.4         4.6         4.1   \n",
       "8            Gujarat        23.4        22.3        20.6        18.9   \n",
       "9            Haryana        10.2         9.4         8.5         7.8   \n",
       "10  Himachal Pradesh         2.4         2.1         1.9         1.7   \n",
       "11            Jammu          5.5         4.6         3.6         3.6   \n",
       "12         Jharkand         15.2        14.6        12.8        12.5   \n",
       "13        Karnataka         21.9        19.6        17.0        14.9   \n",
       "14            Kerala        10.5         9.8         9.3         8.8   \n",
       "15    Madhya Pradesh        31.8        31.3        28.4        25.9   \n",
       "16       Maharashtra        40.7        35.6        30.4        27.1   \n",
       "17            Odisha        16.0        14.8        13.7        13.1   \n",
       "18           Punjab          9.9         8.4         7.4         6.6   \n",
       "19         Rajastan         31.2        30.1        27.2        25.3   \n",
       "20        Tamil Nadu        23.3        20.6        18.1        16.0   \n",
       "21        Telangana         13.0        11.4        10.4         9.4   \n",
       "22     Uttar Pradesh        95.1        90.3        81.8        74.5   \n",
       "23      Uttarakhand          4.3         4.0         3.6         3.1   \n",
       "24       West Bengal        33.8        28.5        24.9        22.8   \n",
       "25               NaN         NaN         NaN         NaN         NaN   \n",
       "26               NaN         NaN         NaN         NaN         NaN   \n",
       "27               NaN         NaN         NaN         NaN         NaN   \n",
       "28               NaN         NaN         NaN         NaN         NaN   \n",
       "29               NaN         NaN         NaN         NaN         NaN   \n",
       "30               NaN         NaN         NaN         NaN         NaN   \n",
       "31               NaN         NaN         NaN         NaN         NaN   \n",
       "32               NaN         NaN         NaN         NaN         NaN   \n",
       "33               NaN         NaN         NaN         NaN         NaN   \n",
       "34               NaN         NaN         NaN         NaN         NaN   \n",
       "35               NaN         NaN         NaN         NaN         NaN   \n",
       "36               NaN         NaN         NaN         NaN         NaN   \n",
       "37               NaN         NaN         NaN         NaN         NaN   \n",
       "38               NaN         NaN         NaN         NaN         NaN   \n",
       "39               NaN         NaN         NaN         NaN         NaN   \n",
       "40               NaN         NaN         NaN         NaN         NaN   \n",
       "41              2011      2021.0         NaN         NaN         NaN   \n",
       "\n",
       "    Unnamed: 5  Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  Unnamed: 10  \\\n",
       "0      20111.0     20211.0     20311.0     20411.0     20112.0      20212.0   \n",
       "1          NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "2        611.7       751.6       848.2       889.7       104.2        131.1   \n",
       "3         27.2        31.3        32.6        31.9         5.0          6.3   \n",
       "4         15.8        19.0        21.7        22.2         2.1          2.6   \n",
       "5         45.0        60.1        77.9        89.4         7.7          9.4   \n",
       "6         12.7        15.7        17.8        19.0         2.0          2.6   \n",
       "7          9.4        11.3        12.1        11.8         1.1          1.8   \n",
       "8         32.2        38.2        41.9        43.5         4.8          6.7   \n",
       "9         12.9        16.0        17.9        18.6         2.2          2.7   \n",
       "10         3.7         4.3         4.6         4.5         0.7          0.9   \n",
       "11         6.1         7.8         9.3         9.3         0.9          1.2   \n",
       "12        15.5        19.8        24.1        26.2         2.4          3.2   \n",
       "13        33.4        38.8        41.2        40.8         5.8          7.3   \n",
       "14        18.8        20.0        20.3        20.0         4.2          5.8   \n",
       "15        35.1        44.3        51.4        56.2         5.7          6.9   \n",
       "16        60.5        71.2        76.6        75.4        11.1         13.9   \n",
       "17        21.9        25.7        28.1        28.7         4.0          4.9   \n",
       "18        15.0        17.7        18.6        18.3         2.9          3.7   \n",
       "19        32.3        42.0        50.0        55.1         5.1          6.5   \n",
       "20        41.3        45.5        46.3        44.2         7.5         10.1   \n",
       "21        18.9        22.6        24.2        24.0         3.2          4.0   \n",
       "22        89.1       120.9       145.0       162.2        15.6         18.1   \n",
       "23         4.9         6.3         7.1         7.7         0.9          1.1   \n",
       "24        49.7        58.5        62.2        60.9         7.8         10.8   \n",
       "25         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "26         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "27         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "28         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "29         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "30         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "31         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "32         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "33         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "34         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "35         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "36         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "37         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "38         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "39         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "40         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "41         NaN         NaN         NaN         NaN         NaN          NaN   \n",
       "\n",
       "    Unnamed: 11  Unnamed: 12  \n",
       "0       20312.0      20412.0  \n",
       "1           NaN          NaN  \n",
       "2         179.3        239.4  \n",
       "3           8.3         10.9  \n",
       "4           3.9          5.5  \n",
       "5          12.7         17.8  \n",
       "6           3.5          4.7  \n",
       "7           2.9          4.3  \n",
       "8           9.5         12.8  \n",
       "9           3.6          5.0  \n",
       "10          1.2          1.7  \n",
       "11          1.9          2.7  \n",
       "12          4.4          6.0  \n",
       "13          9.9         13.0  \n",
       "14          7.6          9.0  \n",
       "15          9.4         12.7  \n",
       "16         18.8         25.2  \n",
       "17          6.5          8.3  \n",
       "18          4.9          6.4  \n",
       "19          9.0         12.3  \n",
       "20         13.7         17.5  \n",
       "21          5.4          7.4  \n",
       "22         23.8         32.3  \n",
       "23          1.5          2.0  \n",
       "24         15.6         20.5  \n",
       "25          NaN          NaN  \n",
       "26          NaN          NaN  \n",
       "27          NaN          NaN  \n",
       "28          NaN          NaN  \n",
       "29          NaN          NaN  \n",
       "30          NaN          NaN  \n",
       "31          NaN          NaN  \n",
       "32          NaN          NaN  \n",
       "33          NaN          NaN  \n",
       "34          NaN          NaN  \n",
       "35          NaN          NaN  \n",
       "36          NaN          NaN  \n",
       "37          NaN          NaN  \n",
       "38          NaN          NaN  \n",
       "39          NaN          NaN  \n",
       "40          NaN          NaN  \n",
       "41          NaN          NaN  >"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                         State         2021         2031         2041  \\\n",
       "0                       India   932.285714   931.285714   930.285714   \n",
       "1   Andaman & Nicobar Islands   938.714286   988.178571  1037.642857   \n",
       "2              Andhra Pradesh   981.714286   982.071429   982.428571   \n",
       "3           Arunachal Pradesh   889.677551   888.824490   887.971429   \n",
       "4                       Assam   969.714286   985.035714  1000.357143   \n",
       "5                       Bihar   883.714286   867.000000   850.285714   \n",
       "6                  Chandigarh   819.714286   834.071428   848.428571   \n",
       "7                Chhattisgarh   977.285714   971.928571   966.571429   \n",
       "8        Dadra & Nagar Haveli   793.571429   762.392857   731.214286   \n",
       "9                 Daman & Diu   597.571429   505.821429   414.071429   \n",
       "10                      Delhi   868.000000   882.214286   896.428571   \n",
       "11                        Goa   908.857143   884.250000   859.642857   \n",
       "12                    Gujarat   914.571429   909.607143   904.642857   \n",
       "13                    Haryana   869.857143   870.142857   870.428571   \n",
       "14           Himachal Pradesh   993.571429  1002.785714  1012.000000   \n",
       "15            Jammu & Kashmir   898.857143   902.214286   905.571429   \n",
       "16                  Jharkhand   931.000000   927.428571   923.857143   \n",
       "17                  Karnataka   968.428571   969.714286   971.000000   \n",
       "18                     Kerala  1076.571429  1085.857143  1095.142857   \n",
       "19                Lakshadweep   911.857143   895.071429   878.285714   \n",
       "20             Madhya Pradesh   914.857143   912.142857   909.428571   \n",
       "21                Maharashtra   924.142857   922.000000   919.857143   \n",
       "22                    Manipur   955.714286   947.285714   938.857143   \n",
       "23                  Meghalaya   985.857143   993.107143  1000.357143   \n",
       "24                    Mizoram   911.285714   898.142857   885.000000   \n",
       "25                   Nagaland   875.428571   866.321429   857.214286   \n",
       "26                     Odisha   958.571429   951.285714   944.000000   \n",
       "27                 Puducherry  1003.000000  1002.535714  1002.071429   \n",
       "28                     Punjab   901.285714   908.928571   916.571429   \n",
       "29                  Rajasthan   923.428571   925.071429   926.714286   \n",
       "30                     Sikkim   865.428571   862.071429   858.714286   \n",
       "31                 Tamil Nadu   980.571429   978.892857   977.214286   \n",
       "32                    Tripura   968.571429   975.785714   983.000000   \n",
       "33              Uttar Pradesh   893.285714   893.071429   892.857143   \n",
       "34                Uttarakhand   959.857143   963.250000   966.642857   \n",
       "35                West Bengal   962.714286   976.750000   990.785714   \n",
       "\n",
       "           2051  \n",
       "0    929.285714  \n",
       "1   1087.107143  \n",
       "2    982.785714  \n",
       "3    887.118367  \n",
       "4   1015.678571  \n",
       "5    833.571429  \n",
       "6    862.785714  \n",
       "7    961.214286  \n",
       "8    700.035714  \n",
       "9    322.321429  \n",
       "10   910.642857  \n",
       "11   835.035714  \n",
       "12   899.678571  \n",
       "13   870.714286  \n",
       "14  1021.214286  \n",
       "15   908.928571  \n",
       "16   920.285714  \n",
       "17   972.285714  \n",
       "18  1104.428571  \n",
       "19   861.500000  \n",
       "20   906.714286  \n",
       "21   917.714286  \n",
       "22   930.428571  \n",
       "23  1007.607143  \n",
       "24   871.857143  \n",
       "25   848.107143  \n",
       "26   936.714286  \n",
       "27  1001.607143  \n",
       "28   924.214286  \n",
       "29   928.357143  \n",
       "30   855.357143  \n",
       "31   975.535714  \n",
       "32   990.214286  \n",
       "33   892.642857  \n",
       "34   970.035714  \n",
       "35  1004.821429  >"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prese.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of               States  2011   2021  2031  2041\n",
       "0                NaN   NaN    NaN   NaN   NaN\n",
       "1     Andhra Pradesh  65.8  66.30  67.0  67.9\n",
       "2              Assam  61.9  62.20  62.7  63.3\n",
       "3              Bihar  65.8  66.30  67.2  67.7\n",
       "4       Chhattisgarh  62.4  62.90  63.3  63.7\n",
       "5              Delhi  71.1  72.40  72.8  73.0\n",
       "6            Gujarat  66.8  67.30  67.7  68.2\n",
       "7            Haryana  67.0  67.30  67.6  68.2\n",
       "8   Himachal Pradesh  70.0  70.10  70.5  71.0\n",
       "9    Jammu & Kashmir  70.1  70.50  71.0  72.0\n",
       "10         Jharkhand  63.4  64.10  65.8  66.1\n",
       "11         Karnataka  67.2  67.50  68.0  68.5\n",
       "12            Kerala  74.2  74.40  74.7  74.8\n",
       "13    Madhya Pradesh  62.4  62.80  63.3  63.8\n",
       "14       Maharashtra  69.9  70.30  70.8  71.3\n",
       "15            Odisha  63.0  63.70  64.3  64.8\n",
       "16            Punjab  69.3  69.80  70.3  71.1\n",
       "17         Rajasthan  66.5  66.80  67.2  67.5\n",
       "18        Tamil Nadu  68.9  69.40  69.8  70.2\n",
       "19     Uttar Pradesh  62.7  63.00  63.5  63.8\n",
       "20       Uttarakhand  69.2  70.20  70.8  71.4\n",
       "21       West Bengal  69.0  69.40  69.7  69.9\n",
       "22             India  66.9  67.13  67.0  67.5>"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "life.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
